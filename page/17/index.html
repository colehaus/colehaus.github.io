<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.9">
    <title>Page 17—ColEx</title>
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,300,700,400italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="../../css/default.css" />
    <link rel="icon" href="../../images/favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="../../images/favicon.ico" type="image/x-icon" />
    <script>
     if (!location.host.startsWith('localhost')) {
       var _rollbarConfig = {
         checkIgnore: function(isUncaught, args, payload) {
           return location.host.startsWith('localhost')
         },
         accessToken: "137e3ab64049469ba4a7d5e13a6f5aeb",
         captureUncaught: true,
         payload: {
           environment: "production"
         }
       };
       !function(r){function o(n){if(e[n])return e[n].exports;var t=e[n]={exports:{},id:n,loaded:!1};return r[n].call(t.exports,t,t.exports,o),t.loaded=!0,t.exports}var e={};return o.m=r,o.c=e,o.p="",o(0)}([function(r,o,e){"use strict";var n=e(1),t=e(4);_rollbarConfig=_rollbarConfig||{},_rollbarConfig.rollbarJsUrl=_rollbarConfig.rollbarJsUrl||"https://cdnjs.cloudflare.com/ajax/libs/rollbar.js/2.3.1/rollbar.min.js",_rollbarConfig.async=void 0===_rollbarConfig.async||_rollbarConfig.async;var a=n.setupShim(window,_rollbarConfig),l=t(_rollbarConfig);window.rollbar=n.Rollbar,a.loadFull(window,document,!_rollbarConfig.async,_rollbarConfig,l)},function(r,o,e){"use strict";function n(r){return function(){try{return r.apply(this,arguments)}catch(r){try{console.error("[Rollbar]: Internal error",r)}catch(r){}}}}function t(r,o){this.options=r,this._rollbarOldOnError=null;var e=s++;this.shimId=function(){return e},window&&window._rollbarShims&&(window._rollbarShims[e]={handler:o,messages:[]})}function a(r,o){var e=o.globalAlias||"Rollbar";if("object"==typeof r[e])return r[e];r._rollbarShims={},r._rollbarWrappedError=null;var t=new p(o);return n(function(){o.captureUncaught&&(t._rollbarOldOnError=r.onerror,i.captureUncaughtExceptions(r,t,!0),i.wrapGlobals(r,t,!0)),o.captureUnhandledRejections&&i.captureUnhandledRejections(r,t,!0);var n=o.autoInstrument;return(void 0===n||n===!0||"object"==typeof n&&n.network)&&r.addEventListener&&(r.addEventListener("load",t.captureLoad.bind(t)),r.addEventListener("DOMContentLoaded",t.captureDomContentLoaded.bind(t))),r[e]=t,t})()}function l(r){return n(function(){var o=this,e=Array.prototype.slice.call(arguments,0),n={shim:o,method:r,args:e,ts:new Date};window._rollbarShims[this.shimId()].messages.push(n)})}var i=e(2),s=0,d=e(3),c=function(r,o){return new t(r,o)},p=d.bind(null,c);t.prototype.loadFull=function(r,o,e,t,a){var l=function(){var o;if(void 0===r._rollbarDidLoad){o=new Error("rollbar.js did not load");for(var e,n,t,l,i=0;e=r._rollbarShims[i++];)for(e=e.messages||[];n=e.shift();)for(t=n.args||[],i=0;i<t.length;++i)if(l=t[i],"function"==typeof l){l(o);break}}"function"==typeof a&&a(o)},i=!1,s=o.createElement("script"),d=o.getElementsByTagName("script")[0],c=d.parentNode;s.crossOrigin="",s.src=t.rollbarJsUrl,e||(s.async=!0),s.onload=s.onreadystatechange=n(function(){if(!(i||this.readyState&&"loaded"!==this.readyState&&"complete"!==this.readyState)){s.onload=s.onreadystatechange=null;try{c.removeChild(s)}catch(r){}i=!0,l()}}),c.insertBefore(s,d)},t.prototype.wrap=function(r,o,e){try{var n;if(n="function"==typeof o?o:function(){return o||{}},"function"!=typeof r)return r;if(r._isWrap)return r;if(!r._rollbar_wrapped&&(r._rollbar_wrapped=function(){e&&"function"==typeof e&&e.apply(this,arguments);try{return r.apply(this,arguments)}catch(e){var o=e;throw"string"==typeof o&&(o=new String(o)),o._rollbarContext=n()||{},o._rollbarContext._wrappedSource=r.toString(),window._rollbarWrappedError=o,o}},r._rollbar_wrapped._isWrap=!0,r.hasOwnProperty))for(var t in r)r.hasOwnProperty(t)&&(r._rollbar_wrapped[t]=r[t]);return r._rollbar_wrapped}catch(o){return r}};for(var u="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,captureDomContentLoaded,captureLoad".split(","),f=0;f<u.length;++f)t.prototype[u[f]]=l(u[f]);r.exports={setupShim:a,Rollbar:p}},function(r,o){"use strict";function e(r,o,e){if(r){var t;"function"==typeof o._rollbarOldOnError?t=o._rollbarOldOnError:r.onerror&&!r.onerror.belongsToShim&&(t=r.onerror,o._rollbarOldOnError=t);var a=function(){var e=Array.prototype.slice.call(arguments,0);n(r,o,t,e)};a.belongsToShim=e,r.onerror=a}}function n(r,o,e,n){r._rollbarWrappedError&&(n[4]||(n[4]=r._rollbarWrappedError),n[5]||(n[5]=r._rollbarWrappedError._rollbarContext),r._rollbarWrappedError=null),o.handleUncaughtException.apply(o,n),e&&e.apply(r,n)}function t(r,o,e){if(r){"function"==typeof r._rollbarURH&&r._rollbarURH.belongsToShim&&r.removeEventListener("unhandledrejection",r._rollbarURH);var n=function(r){var e=r.reason,n=r.promise,t=r.detail;!e&&t&&(e=t.reason,n=t.promise),o&&o.handleUnhandledRejection&&o.handleUnhandledRejection(e,n)};n.belongsToShim=e,r._rollbarURH=n,r.addEventListener("unhandledrejection",n)}}function a(r,o,e){if(r){var n,t,a="EventTarget,Window,Node,ApplicationCache,AudioTrackList,ChannelMergerNode,CryptoOperation,EventSource,FileReader,HTMLUnknownElement,IDBDatabase,IDBRequest,IDBTransaction,KeyOperation,MediaController,MessagePort,ModalWindow,Notification,SVGElementInstance,Screen,TextTrack,TextTrackCue,TextTrackList,WebSocket,WebSocketWorker,Worker,XMLHttpRequest,XMLHttpRequestEventTarget,XMLHttpRequestUpload".split(",");for(n=0;n<a.length;++n)t=a[n],r[t]&&r[t].prototype&&l(o,r[t].prototype,e)}}function l(r,o,e){if(o.hasOwnProperty&&o.hasOwnProperty("addEventListener")){for(var n=o.addEventListener;n._rollbarOldAdd&&n.belongsToShim;)n=n._rollbarOldAdd;var t=function(o,e,t){n.call(this,o,r.wrap(e),t)};t._rollbarOldAdd=n,t.belongsToShim=e,o.addEventListener=t;for(var a=o.removeEventListener;a._rollbarOldRemove&&a.belongsToShim;)a=a._rollbarOldRemove;var l=function(r,o,e){a.call(this,r,o&&o._rollbar_wrapped||o,e)};l._rollbarOldRemove=a,l.belongsToShim=e,o.removeEventListener=l}}r.exports={captureUncaughtExceptions:e,captureUnhandledRejections:t,wrapGlobals:a}},function(r,o){"use strict";function e(r,o){this.impl=r(o,this),this.options=o,n(e.prototype)}function n(r){for(var o=function(r){return function(){var o=Array.prototype.slice.call(arguments,0);if(this.impl[r])return this.impl[r].apply(this.impl,o)}},e="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,_createItem,wrap,loadFull,shimId,captureDomContentLoaded,captureLoad".split(","),n=0;n<e.length;n++)r[e[n]]=o(e[n])}e.prototype._swapAndProcessMessages=function(r,o){this.impl=r(this.options);for(var e,n,t;e=o.shift();)n=e.method,t=e.args,this[n]&&"function"==typeof this[n]&&("captureDomContentLoaded"===n||"captureLoad"===n?this[n].apply(this,[t[0],e.ts]):this[n].apply(this,t));return this},r.exports=e},function(r,o){"use strict";r.exports=function(r){return function(o){if(!o&&!window._rollbarInitialized){r=r||{};for(var e,n,t=r.globalAlias||"Rollbar",a=window.rollbar,l=function(r){return new a(r)},i=0;e=window._rollbarShims[i++];)n||(n=e.handler),e.handler._swapAndProcessMessages(l,e.messages);window[t]=n,window._rollbarInitialized=!0}}}}]);
     }
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-113913768-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-113913768-1');
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          displayAlign: "left",
          displayIndent: "2em"
        });
    </script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG"></script>

    <script type="text/javascript">
if (/Trident/.test(navigator.userAgent)) {
  alert('I have reports that certain features are broken on Internet Explorer ' +
        '(e.g. SVG paths with markers, flexbox with the \'order\' attribute). ' +
        'This is a "Won\'t fix" at the moment so, if you\'re using IE, ' +
        'browse at your own risk.');
}
</script>
</head>
<body>
<div id="underlay">
<main><ul class="teasers">
  
    <li><article class="teaser">
        <h2><a href="../../posts/uncertainty-analysis-of-givewell-cea/">Uncertainty analysis of GiveWell's cost-effectiveness analysis</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/statistics/">statistics</a></li>
    
      <li><a href="../../tag/development/">development</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="../../series/GiveWell%2520cost-effectiveness%2520analysis%2520analysis/">Series: GiveWell cost-effectiveness analysis analysis</a></nav>
        
        <span class="date">Published on <time datetime="September 27, 2019">September 27, 2019</time>.</span>
       </div>

       
         <div class="abstract"><p>GiveWell produces cost-effectiveness models of its top charities. These models take as inputs many uncertain parameters. Instead of representing those uncertain parameters with point estimates—as the cost-effectiveness analysis spreadsheet does—we can (should) represent them with probability distributions. Feeding probability distributions into the models allows us to output explicit probability distributions over the value per dollar corresponding to each charity.</p></div>
       

        <h3 id="givewells-cost-effectiveness-analysis">GiveWell’s cost-effectiveness analysis</h3>
<p><a href="https://www.givewell.org/">GiveWell</a>, an in-depth charity evaluator, makes their detailed spreadsheets models <a href="https://docs.google.com/spreadsheets/d/1d255LKz11L3V-OgOEns9WvJzpnVeaLTcEP1HD4lC478/edit#gid=1537947274">available</a> for public review. These spreadsheets estimate the value per dollar of donations to their 8 top charities: GiveDirectly, Deworm the World, Schistosomiasis Control Initiative, Sightsavers, Against Malaria Foundation, Malaria Consortium, Helen Keller International, and the END Fund. For each charity, a model is constructed taking input values to an estimated value per dollar of donation to that charity. The inputs to these models vary from parameters like “malaria prevalence in areas where AMF operates” to “value assigned to averting the death of an individual under 5”.</p>
<p>Helpfully, GiveWell isolates the input parameters it deems as most uncertain. These can be found in the “User inputs” and “Moral weights” tabs of their spreadsheet. Outsiders interested in the top charities can reuse GiveWell’s model but supply their own perspective by adjusting the values of the parameters in these tabs.</p>
<p>For example, if I go to the “Moral weights” tab and run the calculation with a 0.1 value for doubling consumption for one person for one year—instead of the default value of 1—I see the effect of this modification on the final results: deworming charities look much less effective since their primary effect is on income.</p>
<h3 id="uncertain-inputs">Uncertain inputs</h3>
<p>GiveWell provides the ability to adjust these input parameters and observe altered output because the inputs are fundamentally uncertain. But our uncertainty means that picking any particular value as input for the calculation misrepresents our state of knowledge. From a <a href="https://en.wikipedia.org/wiki/Bayesian_probability">subjective Bayesian</a> point of view, the best way to represent our state of knowledge on the input parameters is with a <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> over the values the parameter could take. Once we do this, we can feed these distributions into the model and, in principle, we’ll end up with a probability distribution over our results. This probability distribution on the results helps us understand the uncertainty contained in our estimates and <a href="https://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/">how literally</a> we should take them.</p>
<h4 id="is-this-really-necessary">Is this really necessary?</h4>
<p>Perhaps that sounds complicated. How are we supposed to multiply, add and otherwise manipulate arbitrary probability distributions in the way our models require? Can we somehow reduce our uncertain beliefs about the input parameters to point estimates and run the calculation on those? One candidate is to take the single most likely value of each input and using that value in our calculations. This is the approach the current cost-effectiveness analysis takes (assuming you provide input values selected in this way). Unfortunately, the output of running the model on these inputs is necessarily a point value and gives no information about the uncertainty of the results. A second possibility is to take lower bounds on the input parameters and run the calculation on these values, and to take the upper bounds on the input parameters and run the calculation on these values. This will produce two bounding values on our results, but it’s hard to give them a useful meaning. If the lower and upper bounds on our inputs describe, for example, a 95% confidence interval, the lower and upper bounds on the result don’t (usually) describe a 95% confidence interval.</p>
<h4 id="computers-are-nice">Computers are nice</h4>
<p>If we had to proceed analytically, working with probability distributions throughout the model would indeed be troublesome and we might have to settle for one of the above approaches. But we live in the future. We can use computers and <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo methods</a> to numerically approximate the results of working with probability distributions while leaving our models clean and unconcerned with these probabilistic details. <a href="https://www.getguesstimate.com/">Guesstimate</a> is a tool that works along these lines and bills itself as “A spreadsheet for things that aren’t certain”.</p>
<h3 id="analysis">Analysis</h3>
<p>We have the beginnings of a plan then. We can implement GiveWell’s cost-effectiveness models in a Monte Carlo framework (<a href="https://docs.pymc.io/">PyMC3</a> in this case), specify probability distributions over the input parameters, and finally run the calculation and look at the uncertainty that’s been propagated to the results.</p>


        <a href="../../posts/uncertainty-analysis-of-givewell-cea/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/conditioning-causal-graphs/">Conditioning in causal graphs</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/causality/">causality</a></li>
    
      <li><a href="../../tag/interactive/">interactive</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="../../series/Graphical%2520causal%2520models/">Series: Graphical causal models</a></nav>
        
        <span class="date">Published on <time datetime="July 18, 2019">July 18, 2019</time>.</span>
       </div>

       

        <p>As mentioned in the warnings on the <a href="../../posts/babys-first-graphical-causal-models/">first post on graphical causal models</a>, I’ve been lying to you so far. But it was for a good reason: that sweet, sweet expository simplicity. So far, all our definitions, algorithms, etc. have proceeded without any acknowledgment of the social scientists’ favorite statistical tool: <span class="noted"><a href="https://en.wikipedia.org/wiki/Controlling_for_a_variable">controlling for a variable</a></span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>In this post, we’ll introduce the concept of conditioning to our graphical causal models framework and see how it both complicates things and offers new possibilities. (This post deliberately mirrors the structure of <a href="../../posts/babys-first-graphical-causal-models/">that one</a> so it may be handy to have it open in a second tab/window for comparison purposes.)</p>
<h3 id="causal-triplets-again">Causal triplets, again</h3>
<p>We started out by talking about three types of causal triplets: chains, forks and inverted forks. For convenience, here is the summary table we ended up with:</p>
<figure class="triplets-table">
<figcaption>
Types of causal triplets
</figcaption>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Name of triplet</th>
<th style="text-align: left;">Name of central vertex</th>
<th style="text-align: left;">Diagram</th>
<th style="text-align: left;">Ends (A and C) dependent?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Chain</td>
<td style="text-align: left;">Mediator/Traverse</td>
<td style="text-align: left;">A → B → C</td>
<td style="text-align: left;">Causally (probably)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Fork</td>
<td style="text-align: left;">Confounder/Common cause</td>
<td style="text-align: left;">A ← B → C</td>
<td style="text-align: left;">Noncausally</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Inverted fork</td>
<td style="text-align: left;">Collider/Common effect</td>
<td style="text-align: left;">A → B ← C</td>
<td style="text-align: left;">No</td>
</tr>
</tbody>
</table>
</figure>
<p>When we add the possibility of conditioning, things change dramatically:</p>
<figure class="triplets-table">
<figcaption>
Types of causal triplets with conditioning on central vertex
</figcaption>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Name of triplet</th>
<th style="text-align: left;">Name of central vertex</th>
<th style="text-align: left;">Diagram</th>
<th style="text-align: left;">Ends (A and C) dependent?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Chain</td>
<td style="text-align: left;">Mediator/Traverse</td>
<td style="text-align: left;">A → B → C</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">Fork</td>
<td style="text-align: left;">Confounder/Common cause</td>
<td style="text-align: left;">A ← B → C</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Inverted fork</td>
<td style="text-align: left;">Collider/common effect</td>
<td style="text-align: left;">A → B ← C</td>
<td style="text-align: left;">Noncausally</td>
</tr>
</tbody>
</table>
</figure>
<p>The complete reversal of in/dependence occasioned by conditioning on the middle vertex may be a bit surprising. There’s a certain reflex that says when ever you want to draw a clean story out of messy data, conditioning on more stuff will help you. But as we see here, <span class="noted">that’s not generally true</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>


        <a href="../../posts/conditioning-causal-graphs/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/instrumental-variables-on-causal-graphs/">Instrumental variables on causal graphs</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/causality/">causality</a></li>
    
      <li><a href="../../tag/interactive/">interactive</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="../../series/Graphical%2520causal%2520models/">Series: Graphical causal models</a></nav>
        
        <span class="date">Published on <time datetime="June 20, 2019">June 20, 2019</time>.</span>
       </div>

       

        <p><a href="../../posts/flip-it-reverse-it-graphical-causal-models/">Last time</a> we talked about viewing d-separation as a tool for model selection. But we’re pretty limited in the causal models we can distinguish between by only observing our variables of interest—any two graphs with the same set of d-separations are indistinguishable. <a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation">Instrumental variables</a> are a common tool for trying to get around the limitations of purely observational data.</p>
<h3 id="instrumental-variables">Instrumental variables</h3>
<p>Instrumental variables (IV) are variables that we’re not intrinsically interested in but that we look at in an attempt to suss out causality. The instrument must be correlated with our cause, but its only impact on the effect should be via the cause.</p>
<p>The classic example is about—you guessed it—smoking. Because running an RCT on smoking is ethically verboten, we’re limited to observational data. How can we determine if smoking causes lung cancer from observational data alone? An instrumental variable! To reiterate, we want a factor that affects smoking prevalence but (almost certainly) does not affect lung cancer in other ways. Finding an instrument that satisfies the <abbr title="instrumental variable">IV</abbr> criteria generally seems to require substantial creativity. Can you think of an instrument for the causal effect of smoking on lung cancer?</p>
<p>…</p>
<p>An instrument that meets these criteria is a tax on cigarettes. We expect smoking to decrease as taxes increase, but it seems hard to imagine a cigarette tax otherwise having an effect on lung cancer.</p>
<h3 id="instrumental-variables-on-causal-graphs">Instrumental variables on causal graphs</h3>
<p>Okay, so that’s what <abbr title="instrument variable">IV</abbr>s are at a high level. But what are they concretely in the graphical causal model setting we’ve been developing?</p>
<h4 id="a-brief-notational-interlude">A brief notational interlude</h4>
<p>We’ll get this out of the way here:</p>
<ul>
<li><span class="math inline">\(\perp\!\!\!\perp\)</span> is the symbol for d-separation</li>
<li>Once we add the strikethrough, <span class="math inline">\(\not\!\!{\perp\!\!\!\perp}\)</span> mean d-connected.</li>
<li>If <span class="math inline">\(G\)</span> is a graph, <span class="math inline">\(G_{\overline{X}}\)</span>, is <span class="math inline">\(G\)</span> in which <span class="noted">all the edges pointing to vertex X have been removed</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</li>
</ul>
<h4 id="defined">Defined</h4>
<p>We’ll start with the definition and then try to build up a feel for it. An instrumental variable X for the causal effect of Y on Z in graph G must be:</p>
<ol type="1">
<li>d-connected to our cause Y—<span class="math inline">\((X \not\!\!{\perp\!\!\!\perp} Y)_G\)</span></li>
<li>d-separated from our effect Z after severing the cause Y from all its parents—<span class="math inline">\((X \perp\!\!\!\perp Z)_{G_\overline{Y}}\)</span></li>
</ol>


        <a href="../../posts/instrumental-variables-on-causal-graphs/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/flip-it-reverse-it-graphical-causal-models/">Flip it and reverse it</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/causality/">causality</a></li>
    
      <li><a href="../../tag/interactive/">interactive</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="../../series/Graphical%2520causal%2520models/">Series: Graphical causal models</a></nav>
        
        <span class="date">Published on <time datetime="June 17, 2019">June 17, 2019</time>.</span>
       </div>

       
         <div class="abstract"><p>Last time we found the d-separations that correspond to a graph. This time, we find the graphs that correspond to a set of d-separations. Which is more useful because we generally know d-separations and generally don’t know graphs.</p></div>
       

        <p><a href="../../posts/babys-first-graphical-causal-models/">Last time</a> we talked about causal graphs, what d-separation and d-connection mean, and how to infer these properties from a causal graph. But this isn’t terribly useful because it requires that we have a fully specified causal graph. If we’re performing research in new or uncertain areas, we have data rather than a causal graph. And this data tells us about d-separations (variables that are independent of each other) and d-connections (variables that are correlated). So our work last time was exactly backwards: graphs to d-separations. This time we’ll go from d-separations to graphs.</p>
<h3 id="model-selection">Model selection</h3>
<p>One way to think about d-separation and d-connection is as helping us with model selection. Last time we presented</p>
<figure>
<img src="../../images/smoking-graph.svg" alt="Smoking is causally associated with both lung cancer and yellow fingers" id="smoking-graph" /><figcaption>Smoking is causally associated with both lung cancer and yellow fingers</figcaption>
</figure>
<p>as one possible causal model regarding smoking. But it’s not the only possibility. We might also be worried that the true causal structure looks like this (just go with it):</p>
<figure>
<img src="../../images/smoking-graph-silly.svg" alt="Yellow fingers are independently caused by smoking and lung cancer" id="smoking-graph-silly" /><figcaption>Yellow fingers are independently caused by smoking and lung cancer</figcaption>
</figure>
<p>How can we tell them apart? Can we use observational data alone? In this case, observational data alone is enough to distinguish between these two causal models! The key is that the two models have different sets of d-separations. In the original model, all the vertices are d-connected and there are no d-separations (this must be the case since there are no colliders). In the second (silly) model, “smoking” and “lung cancer” are d-separated because “yellow fingers” is a collider between them. If our data show that smoking and lung cancer are independent, we must rule out the first model and prefer the second. If the two variables are correlated, we must rule out the second model and prefer the first.</p>
<p>This is a procedure that works generally:</p>
<ol type="1">
<li>Draw out the plausible graphical causal models that include all the variables you have data on</li>
<li>Determine the d-separations for each plausible model</li>
<li>Determine the variables in your data that are independent</li>
<li>Retain the models from step 1 whose d-separations in step 2 are compatible with the data analysis in step 3</li>
</ol>
<p>The ideal is that there’s only one model left at the end of step 4. However, it’s possible to end up with none. This means that step 1 wasn’t permissive enough and more models need to be considered. It’s also possible to end up with more than one model. Not all models are distinguishable by observational data alone. This occurs whenever two models have the same set of d-separations.</p>


        <a href="../../posts/flip-it-reverse-it-graphical-causal-models/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/assorted-links-xiv/">Assorted links XIV</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/links/">links</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="June 14, 2019">June 14, 2019</time>.</span>
       </div>

       

        <ol type="1">
<li><a href="https://www.nature.com/articles/s41467-019-10306-w">Augmented manipulation ability in humans with six-fingered hands</a></li>
</ol>
<blockquote>
<p>can the human brain deal with the complexity to control an extra limb and yield advantages from it? […] Anatomical MRI of the supernumerary finger (SF) revealed that it is actuated by extra muscles and nerves, and fMRI identified a distinct cortical representation of the SF. […] Polydactyly subjects were able to coordinate the SF with their other fingers for more complex movements than five fingered subjects, and so carry out with only one hand tasks normally requiring two hands.</p>
</blockquote>
<ol start="2" type="1">
<li><a href="http://spiritleveldelusion.blogspot.com/2019/03/the-spirit-level-ten-years-on.html">The Spirit Level ten years on</a></li>
</ol>
<blockquote>
<p>In summary, most of the biggest claims made by Wilkinson and Pickett in The Spirit Level look even weaker today than they did when the book was published. Only one of the six associations stand up under W &amp; P’s own methodology and none of them stand up when the full range of countries is analysed. In the case of life expectancy - the very flagship of The Spirit Level - the statistical association is the opposite of what the hypothesis predicts.</p>
</blockquote>
<blockquote>
<p>If The Spirit Level hypothesis were correct, it would produce robust and consistent results over time as the underlying data changes. Instead, it seems to be extremely fragile, only working when a very specific set of statistics are applied to a carefully selected list of countries.</p>
</blockquote>
<ol start="3" type="1">
<li><a href="https://twitter.com/backus/status/1110331165007704069">I’ve been called out</a></li>
</ol>
<blockquote>
<p>The allure of “meta” and “axiomatic first principles” is that it’s kinda like get-rich-quick thinking but for epistemics. Get a few abstractions really right and potentially earn more than you would grinding as an object-level wage slave for decades.</p>
</blockquote>
<ol start="4" type="1">
<li><a href="https://phenomenalworld.org/metaresearch/experiments-for-policy-choice">Experiments for Policy Choice</a></li>
</ol>
<blockquote>
<p>Trying to identify the best policy is different from estimating the precise impact of every individual policy: as long as we can identify the best policy, we do not care about the precise impacts of inferior policies. Yet, despite this, most experiments follow protocols that are designed to figure out the impact of every policy, even the obviously inferior ones.</p>
</blockquote>
<ol start="5" type="1">
<li><a href="https://www.sciencemag.org/news/2016/12/six-cloned-horses-help-rider-win-prestigious-polo-match">Six cloned horses help rider win prestigious polo match</a></li>
</ol>
<blockquote>
<p>Cambiaso rode six different horses to help his team win. […] What is noteworthy is that all six horses were clones of the same mare—they’re named Cuartetera 01 through 06. […] “Every scientist that deals with epigenetics told me this would never work,” says Meeker</p>
</blockquote>


        <a href="../../posts/assorted-links-xiv/" class="full-post">Full post</a>

    </article></li>
    
</ul></main>

<nav class="pagination top">
  <ul>
  
    <li><a title="Oldest" href="../../page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="../../page/16/">⇠</a></li>
  
  
    <li><a title="Newer" href="../../page/18/">⇢</a></li>
  
  
    <li><a title="Newest" href="../../page/18/">⇥</a></li>
  
</ul>

</nav>
<nav class="pagination bottom">
  <ul>
  
    <li><a title="Oldest" href="../../page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="../../page/16/">⇠</a></li>
  
  
    <li><a title="Newer" href="../../page/18/">⇢</a></li>
  
  
    <li><a title="Newest" href="../../page/18/">⇥</a></li>
  
</ul>

</nav>


<header>
  <h1>Collectively Exhaustive</h1><span>A weblog</span>
  <hr />
</header>

<div class="main-menu top">
  <nav><ul>
    
      <li><a href="../../">Home</a></li>
    
    
      <li><a href="../../posts/">By date</a></li>
    
    
      <li><a href="../../tags/">By tag</a></li>
    
    
      <li><a href="../../series/">By series</a></li>
    
    
      <li><a href="../../tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="../../atom.xml">RSS</a></li>
</ul></nav>

  <hr />
</div>

<div class="main-menu bottom">
  <hr />
  <nav><ul>
    
      <li><a href="../../">Home</a></li>
    
    
      <li><a href="../../posts/">By date</a></li>
    
    
      <li><a href="../../tags/">By tag</a></li>
    
    
      <li><a href="../../series/">By series</a></li>
    
    
      <li><a href="../../tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="../../atom.xml">RSS</a></li>
</ul></nav>

</div>


</div>

  </body>
</html>
