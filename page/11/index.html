<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.9">
    <title>Page 11—ColEx</title>
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,300,700,400italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="../../css/default.css" />
    <link rel="icon" href="../../images/favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="../../images/favicon.ico" type="image/x-icon" />
    <script>
     if (!location.host.startsWith('localhost')) {
       var _rollbarConfig = {
         checkIgnore: function(isUncaught, args, payload) {
           return location.host.startsWith('localhost')
         },
         accessToken: "137e3ab64049469ba4a7d5e13a6f5aeb",
         captureUncaught: true,
         payload: {
           environment: "production"
         }
       };
       !function(r){function o(n){if(e[n])return e[n].exports;var t=e[n]={exports:{},id:n,loaded:!1};return r[n].call(t.exports,t,t.exports,o),t.loaded=!0,t.exports}var e={};return o.m=r,o.c=e,o.p="",o(0)}([function(r,o,e){"use strict";var n=e(1),t=e(4);_rollbarConfig=_rollbarConfig||{},_rollbarConfig.rollbarJsUrl=_rollbarConfig.rollbarJsUrl||"https://cdnjs.cloudflare.com/ajax/libs/rollbar.js/2.3.1/rollbar.min.js",_rollbarConfig.async=void 0===_rollbarConfig.async||_rollbarConfig.async;var a=n.setupShim(window,_rollbarConfig),l=t(_rollbarConfig);window.rollbar=n.Rollbar,a.loadFull(window,document,!_rollbarConfig.async,_rollbarConfig,l)},function(r,o,e){"use strict";function n(r){return function(){try{return r.apply(this,arguments)}catch(r){try{console.error("[Rollbar]: Internal error",r)}catch(r){}}}}function t(r,o){this.options=r,this._rollbarOldOnError=null;var e=s++;this.shimId=function(){return e},window&&window._rollbarShims&&(window._rollbarShims[e]={handler:o,messages:[]})}function a(r,o){var e=o.globalAlias||"Rollbar";if("object"==typeof r[e])return r[e];r._rollbarShims={},r._rollbarWrappedError=null;var t=new p(o);return n(function(){o.captureUncaught&&(t._rollbarOldOnError=r.onerror,i.captureUncaughtExceptions(r,t,!0),i.wrapGlobals(r,t,!0)),o.captureUnhandledRejections&&i.captureUnhandledRejections(r,t,!0);var n=o.autoInstrument;return(void 0===n||n===!0||"object"==typeof n&&n.network)&&r.addEventListener&&(r.addEventListener("load",t.captureLoad.bind(t)),r.addEventListener("DOMContentLoaded",t.captureDomContentLoaded.bind(t))),r[e]=t,t})()}function l(r){return n(function(){var o=this,e=Array.prototype.slice.call(arguments,0),n={shim:o,method:r,args:e,ts:new Date};window._rollbarShims[this.shimId()].messages.push(n)})}var i=e(2),s=0,d=e(3),c=function(r,o){return new t(r,o)},p=d.bind(null,c);t.prototype.loadFull=function(r,o,e,t,a){var l=function(){var o;if(void 0===r._rollbarDidLoad){o=new Error("rollbar.js did not load");for(var e,n,t,l,i=0;e=r._rollbarShims[i++];)for(e=e.messages||[];n=e.shift();)for(t=n.args||[],i=0;i<t.length;++i)if(l=t[i],"function"==typeof l){l(o);break}}"function"==typeof a&&a(o)},i=!1,s=o.createElement("script"),d=o.getElementsByTagName("script")[0],c=d.parentNode;s.crossOrigin="",s.src=t.rollbarJsUrl,e||(s.async=!0),s.onload=s.onreadystatechange=n(function(){if(!(i||this.readyState&&"loaded"!==this.readyState&&"complete"!==this.readyState)){s.onload=s.onreadystatechange=null;try{c.removeChild(s)}catch(r){}i=!0,l()}}),c.insertBefore(s,d)},t.prototype.wrap=function(r,o,e){try{var n;if(n="function"==typeof o?o:function(){return o||{}},"function"!=typeof r)return r;if(r._isWrap)return r;if(!r._rollbar_wrapped&&(r._rollbar_wrapped=function(){e&&"function"==typeof e&&e.apply(this,arguments);try{return r.apply(this,arguments)}catch(e){var o=e;throw"string"==typeof o&&(o=new String(o)),o._rollbarContext=n()||{},o._rollbarContext._wrappedSource=r.toString(),window._rollbarWrappedError=o,o}},r._rollbar_wrapped._isWrap=!0,r.hasOwnProperty))for(var t in r)r.hasOwnProperty(t)&&(r._rollbar_wrapped[t]=r[t]);return r._rollbar_wrapped}catch(o){return r}};for(var u="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,captureDomContentLoaded,captureLoad".split(","),f=0;f<u.length;++f)t.prototype[u[f]]=l(u[f]);r.exports={setupShim:a,Rollbar:p}},function(r,o){"use strict";function e(r,o,e){if(r){var t;"function"==typeof o._rollbarOldOnError?t=o._rollbarOldOnError:r.onerror&&!r.onerror.belongsToShim&&(t=r.onerror,o._rollbarOldOnError=t);var a=function(){var e=Array.prototype.slice.call(arguments,0);n(r,o,t,e)};a.belongsToShim=e,r.onerror=a}}function n(r,o,e,n){r._rollbarWrappedError&&(n[4]||(n[4]=r._rollbarWrappedError),n[5]||(n[5]=r._rollbarWrappedError._rollbarContext),r._rollbarWrappedError=null),o.handleUncaughtException.apply(o,n),e&&e.apply(r,n)}function t(r,o,e){if(r){"function"==typeof r._rollbarURH&&r._rollbarURH.belongsToShim&&r.removeEventListener("unhandledrejection",r._rollbarURH);var n=function(r){var e=r.reason,n=r.promise,t=r.detail;!e&&t&&(e=t.reason,n=t.promise),o&&o.handleUnhandledRejection&&o.handleUnhandledRejection(e,n)};n.belongsToShim=e,r._rollbarURH=n,r.addEventListener("unhandledrejection",n)}}function a(r,o,e){if(r){var n,t,a="EventTarget,Window,Node,ApplicationCache,AudioTrackList,ChannelMergerNode,CryptoOperation,EventSource,FileReader,HTMLUnknownElement,IDBDatabase,IDBRequest,IDBTransaction,KeyOperation,MediaController,MessagePort,ModalWindow,Notification,SVGElementInstance,Screen,TextTrack,TextTrackCue,TextTrackList,WebSocket,WebSocketWorker,Worker,XMLHttpRequest,XMLHttpRequestEventTarget,XMLHttpRequestUpload".split(",");for(n=0;n<a.length;++n)t=a[n],r[t]&&r[t].prototype&&l(o,r[t].prototype,e)}}function l(r,o,e){if(o.hasOwnProperty&&o.hasOwnProperty("addEventListener")){for(var n=o.addEventListener;n._rollbarOldAdd&&n.belongsToShim;)n=n._rollbarOldAdd;var t=function(o,e,t){n.call(this,o,r.wrap(e),t)};t._rollbarOldAdd=n,t.belongsToShim=e,o.addEventListener=t;for(var a=o.removeEventListener;a._rollbarOldRemove&&a.belongsToShim;)a=a._rollbarOldRemove;var l=function(r,o,e){a.call(this,r,o&&o._rollbar_wrapped||o,e)};l._rollbarOldRemove=a,l.belongsToShim=e,o.removeEventListener=l}}r.exports={captureUncaughtExceptions:e,captureUnhandledRejections:t,wrapGlobals:a}},function(r,o){"use strict";function e(r,o){this.impl=r(o,this),this.options=o,n(e.prototype)}function n(r){for(var o=function(r){return function(){var o=Array.prototype.slice.call(arguments,0);if(this.impl[r])return this.impl[r].apply(this.impl,o)}},e="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,_createItem,wrap,loadFull,shimId,captureDomContentLoaded,captureLoad".split(","),n=0;n<e.length;n++)r[e[n]]=o(e[n])}e.prototype._swapAndProcessMessages=function(r,o){this.impl=r(this.options);for(var e,n,t;e=o.shift();)n=e.method,t=e.args,this[n]&&"function"==typeof this[n]&&("captureDomContentLoaded"===n||"captureLoad"===n?this[n].apply(this,[t[0],e.ts]):this[n].apply(this,t));return this},r.exports=e},function(r,o){"use strict";r.exports=function(r){return function(o){if(!o&&!window._rollbarInitialized){r=r||{};for(var e,n,t=r.globalAlias||"Rollbar",a=window.rollbar,l=function(r){return new a(r)},i=0;e=window._rollbarShims[i++];)n||(n=e.handler),e.handler._swapAndProcessMessages(l,e.messages);window[t]=n,window._rollbarInitialized=!0}}}}]);
     }
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-113913768-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-113913768-1');
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          displayAlign: "left",
          displayIndent: "2em"
        });
    </script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG"></script>

    <script type="text/javascript">
if (/Trident/.test(navigator.userAgent)) {
  alert('I have reports that certain features are broken on Internet Explorer ' +
        '(e.g. SVG paths with markers, flexbox with the \'order\' attribute). ' +
        'This is a "Won\'t fix" at the moment so, if you\'re using IE, ' +
        'browse at your own risk.');
}
</script>
</head>
<body>
<div id="underlay">
<main><ul class="teasers">
  
    <li><article class="teaser">
        <h2><a href="../../posts/ideal-theory-decision-theory/">Ideal theory and decision theory</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/ideal%2520theory/">ideal theory</a></li>
    
      <li><a href="../../tag/decision%2520theory/">decision theory</a></li>
    
      <li><a href="../../tag/political%2520philosophy/">political philosophy</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="../../series/The%2520Tyranny%2520of%2520the%2520Ideal/">Series: The Tyranny of the Ideal</a></nav>
        
        <span class="date">Published on <time datetime="August 15, 2018">August 15, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>The ideal theory debate is actually applied decision theory. The tools and vocabulary of decision theory—at a minimum, the von Neumann-Morgenstern utility theorem, the concept of epistemic risk aversion, and the area of sequential decision theory—are useful in this new domain.</p></div>
       

        <h3 id="ideal-theory">Ideal theory</h3>
<p>If I may editorialize, the ideal theory debate is essentially about how to translate our understanding of justice into actions in the present. Reductively, one side (the idealists) advocates for always moving the world we inhabit closer to the ideally just world while the other side (the non-idealists) advocates for always moving the world we inhabit toward the best adjacent world.</p>
<p>What’s not usually at issue in the ideal theory debate is: our understanding of the status quo, our predictive models of the future, or our notion of justice. That’s not to say that there’s consensus on these issues—far from it. It’s just that discussion of these issues doesn’t fall under the heading of ‘ideal theory’. No one considers themselves to be waging that debate when they talk about currently existing inequality in Germany or what justice recommends with regard to positive and negative rights. By all this I merely mean to emphasize that the scope of the ideal theory debate is rather small—given all the presuppositions above, what algorithm do we employ to choose the next possible world we’ll inhabit?</p>
<p>Hopefully, by framing the ideal theory debate in the foregoing terms, I’ve predisposed you to my point of view: The subject matter of the ideal theory debate is also the subject matter of decision theory. That is, the ideal theory debate is really a debate about applied decision theory.</p>
<h3 id="normative-decision-theory">Normative decision theory</h3>
<p><del><a href="http://www.patheos.com/blogs/religionprof/2016/12/websters-dictionary-defines.html">Webster’s dictionary defines</a></del>—*cough*—<span class="citation" data-cites="hansson1994">(Hansson <a href="#ref-hansson1994">1994</a>)</span> says “decision theory is concerned with goal-directed behaviour in the presence of options”. We’ll try to make this description more comprehensive by appealing to <a href="https://plato.stanford.edu/entries/decision-theory/#SavThe">Leonard Savage’s formalization</a>. The hope is that by describing decision theory fully, we can see how the boundaries of the ideal theory debate line up with the boundaries of decision theory.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/human-cognitive-architecture-learning/">Human cognitive architecture and learning</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/meta%2520monday/">meta monday</a></li>
    
      <li><a href="../../tag/pedagogy/">pedagogy</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="August 13, 2018">August 13, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>Problem-solving relies on working memory. Working memory is very limited except when it comes to information that’s also in long-term memory. Long-term memory is thus central to expertise. Committing things to long-term memory (i.e. learning) is best accomplished by the careful management of cognitive load.</p></div>
       

        <h3 id="preface">Preface</h3>
<p>The following post is basically a straightforward regurgitation of (part of) <span class="citation" data-cites="sweller2008">(Sweller <a href="#ref-sweller2008">2008</a>)</span>. That paper is very readable so there’s really no reason to read the rest of this post. With that out of the way, I liked this paper for two main reasons:</p>
<ul>
<li>It fairly radically changed my opinion on the value of long-term memory in ways that are practically important</li>
<li>It provides a coherent theory which unifies many phenomena. A coherent theory is easier to remember and easier to apply in novel situations than a disparate collection of facts.</li>
</ul>
<h3 id="working-memory">Working memory</h3>
<p>Essentially all human problem-solving is about the manipulation of items in working memory. Alas, our working memory is tragically limited—traditionally, research suggests the upper limit on the number of ‘chunks’ in working memory is the <a href="https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two">“magical number seven”</a>. (Interestingly, there’s some evidence that chimpanzees have superior working memory to humans. <a href="https://www.youtube.com/watch?v=nTgeLEWr614">Video</a> and <a href="https://www.cell.com/current-biology/pdf/S0960-9822(07)02088-X.pdf">paper</a>). Despite this grievous limitation, experience suggests that humans do actually carry out impressive feats of problem-solving. How?</p>
<h3 id="long-term-memory">Long-term memory</h3>
<p>The key is exploiting a ‘loophole’—“huge amounts of organized information can be transferred from long-term memory to working memory without overloading working memory” <span class="citation" data-cites="sweller2008">(Sweller <a href="#ref-sweller2008">2008</a>)</span>. Thus, we arrive at the central importance of long-term memory to human cognition. Contra the denigration of rote memorization, “[task-relevant long-term memory] is the only reliable difference that has been obtained differentiating novices and experts in problem-solving skill and is the only difference required to fully explain why an individual is an expert in solving particular classes of problems” <span class="citation" data-cites="sweller2008">(Sweller <a href="#ref-sweller2008">2008</a>)</span>. In other words, long-term memory is necessary and sufficient to explain expertise.</p>
<h4 id="chess-board-recall">Chess board recall</h4>
<p>We can make illustrate these claims with the results of a classic study <span class="citation" data-cites="degroot2014">(De Groot <a href="#ref-degroot2014">2014</a>)</span>. Look at the next image for a few seconds, close your eyes, and try to recall the positions of pieces.</p>
<figure>
<img src="../../images/chess-real.png" alt="Leko vs. Kramnik, World Championship 2004" class="chess-board" /><figcaption>Leko vs. Kramnik, World Championship 2004</figcaption>
</figure>
<p>If you’re a chess amateur, this should have been quite hard (i.e. you probably misremembered the pieces). On the other hand, if you’re a chess expert, this was probably fairly straightforward.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/assorted-links-vi/">Assorted Links VI</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/links/">links</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="August  4, 2018">August  4, 2018</time>.</span>
       </div>

       

        <ol type="1">
<li><a href="http://www.openculture.com/2017/03/a-human-chess-match-gets-played-in-leningrad-1924.html">A Human Chess Match Gets Played in Leningrad, 1924</a></li>
</ol>
<figure>
<img src="../../images/human-chess-1924.jpg" alt="Human chess match in Leningrad" /><figcaption>Human chess match in Leningrad</figcaption>
</figure>
<ol start="2" type="1">
<li><a href="https://newsinteractives.cbc.ca/longform/dna-ancestry-test">How dog DNA helped uncover a suspected Indian status scam</a></li>
</ol>
<blockquote>
<p>Brabant says he had heard about Côté’s experience, so he sent in a sample of DNA from his French poodle, Mollie, to the same company CAPC uses for DNA testing.</p>
It determined the dog had five per cent Native American ancestry: two per cent Oji-Cree, two per cent Saulteaux and one per cent Mississauga.
</blockquote>
<ol start="3" type="1">
<li><a href="https://twitter.com/SimonDeDeo/status/1017616703864307712">Simon DeDeo on industry ML research</a></li>
</ol>
<blockquote>
<p>I tried to work out what deep learning was about. Most of the candidates were too sleep deprived to dissemble. Basic answer: every sexy project we do—flying quadcopters, getting another 0.1% on the MNIST—is basically one graduate student.</p>
<p>You work out the topology of the neural net. Then you find the weights. How? The answer: “graduate student descent”, a little pun to giggle over floppy croissants at the student cafe—in short, there’s no good answer, a human being sits there and twiddles things about.</p>
Machine learning is an amazing accomplishment of engineering. But it’s not science. Not even close. It’s just 1990, scaled up. It has given us <em>literally</em> no more insight than we had twenty years ago.
</blockquote>
<ol start="4" type="1">
<li><a href="https://www.csiro.au/en/News/News-releases/2018/Trial-wipes-out-more-than-80-per-cent-of-disease-spreading-mozzie">Trial wipes out more than 80 per cent of disease-spreading mozzie</a></li>
</ol>
<blockquote>
<p>“[T]he three mostly deadly types the Aedes, Anopheles and Culex are found almost all over the world and are responsible for around 17 per cent of infectious disease transmissions globally.”</p>
<p>From November 2017 to June this year, non-biting male Aedes aegypti mosquitoes sterilised with the natural bacteria Wolbachia were released in trial zones along the Cassowary Coast in North Queensland.</p>
They mated with local female mosquitoes, resulting in eggs that did not hatch and a significant reduction of their population.
</blockquote>
<ol start="5" type="1">
<li><a href="http://www.wipsociology.org/2018/07/11/how-do-admen-sleep-at-night-responding-to-moral-stigma-in-a-creative-industry/">How do admen sleep at night? responding to moral stigma in a creative industry</a></li>
</ol>
<blockquote>
<p>Which begs the question: why do admen and adwomen stay in their industry, when it’s generally viewed so negatively?</p>
<p>That moral stigma shows up in annual Gallup polls, where American are asked how they would rate “the honesty and ethical standards” of people in different fields. Year after year, advertising practitioners come in around the bottom of that list, right along with members of congress, lobbyists, and car salespeople.</p>
Through the first author’s field observations and interviews, we found that advertising practitioners justified the moral worth of their work through narratives that tied their work to some conception of the common good, emphasizing the good service they believe advertising can provide to society.
</blockquote>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/example-lazy-approach-ai-safety/">An example of the lazy approach to AI safety</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/machine%2520ethics/">machine ethics</a></li>
    
      <li><a href="../../tag/moral%2520uncertainty/">moral uncertainty</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="../../series/Lazy%2520AI%2520safety/">Series: Lazy AI safety</a></nav>
        
        <span class="date">Published on <time datetime="July 10, 2018">July 10, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>The lazy approach to AI safety suggests that we explicitly encode our moral uncertainty into artificial agents. Then agents can decide to undertake moral investigation via value of information calculations. We make the description of this approach more concrete by examining its application in a nearly trivial setting.</p></div>
       

        <p>Examples often clarify. Let’s see an example of the <a href="../../posts/lazy-ai-safety/">lazy approach to AI safety</a> in action.</p>
<h3 id="the-setting">The setting</h3>
<p>Suppose <a href="https://en.wikipedia.org/wiki/The_Professor_(Gilligan%27s_Island)">The Professor</a> has performed another bamboo miracle and built an AI agent on the <a href="https://en.wikipedia.org/wiki/Gilligan%27s_Island">island</a>. Sadly, the castaways forgot the agent in their frantic final escape. So it’s just our agent, alone on an island in the Pacific.</p>
<p>As a man of taste and refinement, the professor has followed the lazy approach to AI safety. As such, the agent’s utility futility is quite simple: The utility of any state of affairs is exactly the moral good of that state of affairs according to whatever turns out to be the <span class="noted">One True Moral Theory (OTMT)</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. In symbols, <span class="math inline">\(u(x) = g(x)\)</span> where <span class="math inline">\(u : X \rightarrow \mathbb{R}\)</span> and <span class="noted"><span class="math inline">\(g : X \rightarrow \mathbb{R}\)</span></span><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> where <span class="math inline">\(X\)</span> is the set of possible states of affairs, <span class="math inline">\(u\)</span> is the utility function, and <span class="math inline">\(g\)</span> evaluates the moral goodness of a state of affairs according to the OTMT.</p>
<p>For simplicity, we’ll suppose there are only two possible interventions the agent can make: <a href="https://en.wiktionary.org/wiki/ze">Ze</a> can harvest coconuts or harvest bamboo. Furthermore, we’ll fiat that there are only two possible moral theories in all the world: the coconut imperative and bamboocentrism. According to the coconut imperative, the goodness of a state of affairs is defined as <span class="math inline">\(g_c(b, c) = 0 \cdot b + 3 \cdot c\)</span> where <span class="math inline">\(c\)</span> is the total number of coconuts that have been harvested and <span class="math inline">\(b\)</span> is the total number of bamboo shoots that have been harvested. On the bamboocentric view of things, <span class="math inline">\(g_b(b, c) = 2 \cdot b + 0 \cdot c\)</span>. (The fact that we only have moral theories which express goodness in terms of real numbers permits our earlier simplification of assuming that the OTMT takes this shape.)</p>
<h3 id="initial-behavior">Initial behavior</h3>
<p>Before the Professor <a href="https://giphy.com/gifs/will-arnett-UGAwRa9KWjO2Q/fullscreen">abandoned his child</a>, he programmed the agent with a uniform prior over all possible ethical theories. That is, the agent thinks there’s a 50% chance bamboocentrism is true and a 50% chance the coconut imperative is the OTMT. Thus, in the absence of better information, the agent spends zir days harvesting coconuts (we assume the resources required to harvest a coconut are identical to the resources required to harvest a bamboo stalk). To be fully explicit:</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="../../posts/false-dichotomy-ideal-theory-debate/">False dichotomies and the ideal theory debate</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="../../tag/ideal%2520theory/">ideal theory</a></li>
    
      <li><a href="../../tag/decision%2520theory/">decision theory</a></li>
    
      <li><a href="../../tag/political%2520philosophy/">political philosophy</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="../../series/The%2520Tyranny%2520of%2520the%2520Ideal/">Series: The Tyranny of the Ideal</a></nav>
        
        <span class="date">Published on <time datetime="July  9, 2018">July  9, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>The dichotomy of ideal and anti-ideal theory is a false one. For each supposedly unique feature of ideal theorizing, there is a scaled-down analogue in non-ideal theory. Furthermore, all the dilemmas in the debate can be fruitfully approached as problems in decision theory.</p></div>
       

        <p>This post is deprecated in favor of <a href="../../posts/ideal-theory-decision-theory">Ideal theory and decision theory</a>.</p>
<h3 id="ideal-and-non-ideal-theory">Ideal and non-ideal theory</h3>
<p>We’ve already described ideal theory in <a href="../../posts/utopia-infinitude-secretaries/">previous posts</a>, but we’ll give a short recap here for the sake of self-sufficiency. Ideal theory suggests that when making decisions about alternative social worlds—that is, about different political and economic institutions, we should have an ideally just society in mind. Non-idealists argue that this information is irrelevant; we only need to be able to perform pairwise comparisons. A popular metaphor in the area is that of mountain climbing. In the language of this metaphor, ideal theorists like <a href="https://en.wikipedia.org/wiki/John_Rawls">John Rawls</a> suggest that mountaineers orient themselves toward Everest while non-idealists like <a href="https://en.wikipedia.org/wiki/Amartya_Sen">Amartya Sen</a> suggest that knowledge of <a href="https://en.wikipedia.org/wiki/Mount_Everest">Everest</a> is irrelevant when comparing the heights of <a href="https://en.wikipedia.org/wiki/Mount_Kilimanjaro">Kilimanjaro</a> and <a href="https://en.wikipedia.org/wiki/Denali">Denali</a>.</p>
<h3 id="thesis">Thesis</h3>
<p>I contend this is a debate which can be <a href="http://askphilosophers.com/question/5254">dissolved</a>. There is no necessary opposition between incrementalism and idealism. Instead, all of these perspectives can be ably unified under the framework of decision theory.</p>
<h3 id="dichotomy">Dichotomy</h3>
<p>Before I can make the argument that’s it’s a <em>false</em> dichotomy, I need to show that it’s a putative dichotomy. There’s little value in attacking <a href="https://en.wikipedia.org/wiki/Straw_man">straw men</a>. Since I’ve just read <span class="citation" data-cites="gaus2016">(Gaus <a href="#ref-gaus2016">2016</a>)</span>, we’ll examine that in detail and expect that it’s representative of the larger discussion.</p>
<p>The boundary that Gaus draws is between worlds in the ‘neighborhood’ of the status quo and those outside it. If we restrict our attention to worlds in the neighborhood, we’re engaging in non-ideal theory, but if we speculate on distant worlds we’re doing ideal theory. What is this key neighborhood concept? In Gaus’s words: “A neighborhood delimits a set of nearby social worlds characterized by relatively similar justice-relevant social structures.”</p>
<p>So we’re already on firm grounds for a claim of dichotomous thinking. On this view, the <span class="noted">structure of the problem is dichotomous</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. But Gaus also demonstrates the dichotomous view when describing the divergent implications of the ideal and non-ideal view:</p>
<blockquote>
[L]ocal optimization often points in a different direction than pursuit of the ideal. We then confront what I have called <span id="the-choice">The Choice</span>: should we turn our back on local optimization and move toward the ideal? [… O]ur judgments within our neighborhood have better warrant than judgments outside of it; if the ideal is outside our current neighborhood, then we are forgoing relatively clear gains in justice for an uncertain prospect that our realistic utopia lies in a different direction. <span class="noted">Mill’s revolutionaries</span><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, certain of their own wisdom and judgment, were more than willing to commit society to the pursuit of their vision of the ideal; their hubris had terrible costs for many.
</blockquote>
<h3 id="similarities">Similarities</h3>
<p>Now, I’ll hope you agree ideal and non-ideal theory are framed as incompatible. On that assumption, I’ll begin to argue against the dichotomy.</p>
<h4 id="uncertainty-all-around">Uncertainty all around</h4>
<p>I do accept Gaus’s Neigborhood Constraint—our knowledge of distant social words is much less reliable than our knowledge of worlds similar to the status quo. Furthermore, I think we have non-trivial uncertainties about the workings and justice of worlds that <em>are</em> nearby. Importantly, (though not, I think, crucially) I don’t see any obvious reason for discontinuities in the reliability of our knowledge. My intuition suggests it drops off smoothly with distance from the status quo <span id="reliability" class="spark"></span>.</p>


    </article></li>
    
</ul></main>

<nav class="pagination top">
  <ul>
  
    <li><a title="Oldest" href="../../page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="../../page/10/">⇠</a></li>
  
  
    <li><a title="Newer" href="../../page/12/">⇢</a></li>
  
  
    <li><a title="Newest" href="../../page/12/">⇥</a></li>
  
</ul>

</nav>
<nav class="pagination bottom">
  <ul>
  
    <li><a title="Oldest" href="../../page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="../../page/10/">⇠</a></li>
  
  
    <li><a title="Newer" href="../../page/12/">⇢</a></li>
  
  
    <li><a title="Newest" href="../../page/12/">⇥</a></li>
  
</ul>

</nav>


<header>
  <h1>Collectively Exhaustive</h1><span>A weblog</span>
  <hr />
</header>

<div class="main-menu top">
  <nav><ul>
    
      <li><a href="../../">Home</a></li>
    
    
      <li><a href="../../posts/">By date</a></li>
    
    
      <li><a href="../../tags/">By tag</a></li>
    
    
      <li><a href="../../series/">By series</a></li>
    
    
      <li><a href="../../tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="../../atom.xml">RSS</a></li>
</ul></nav>

  <hr />
</div>

<div class="main-menu bottom">
  <hr />
  <nav><ul>
    
      <li><a href="../../">Home</a></li>
    
    
      <li><a href="../../posts/">By date</a></li>
    
    
      <li><a href="../../tags/">By tag</a></li>
    
    
      <li><a href="../../series/">By series</a></li>
    
    
      <li><a href="../../tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="../../atom.xml">RSS</a></li>
</ul></nav>

</div>



<script defer type="text/javascript" src="../../js/custom-elements.js"></script>

<script defer type="text/javascript" src="../../js/vendors~custom-elements~false-dichotomy-ideal-theory-debate~ideal-calibration~is-development-easy~qu~30bf37d2.js"></script>

<script defer type="text/javascript" src="../../js/vendors~custom-elements~util-egal.js"></script>

</div>

  </body>
</html>
