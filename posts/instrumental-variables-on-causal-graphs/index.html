<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.9">
    <title>Instrumental variables on causal graphs—ColEx</title>
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,300,700,400italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="../../css/default.css" />
    <link rel="icon" href="../../images/favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="../../images/favicon.ico" type="image/x-icon" />
    <script>
     if (!location.host.startsWith('localhost')) {
       var _rollbarConfig = {
         checkIgnore: function(isUncaught, args, payload) {
           return location.host.startsWith('localhost')
         },
         accessToken: "137e3ab64049469ba4a7d5e13a6f5aeb",
         captureUncaught: true,
         payload: {
           environment: "production"
         }
       };
       !function(r){function o(n){if(e[n])return e[n].exports;var t=e[n]={exports:{},id:n,loaded:!1};return r[n].call(t.exports,t,t.exports,o),t.loaded=!0,t.exports}var e={};return o.m=r,o.c=e,o.p="",o(0)}([function(r,o,e){"use strict";var n=e(1),t=e(4);_rollbarConfig=_rollbarConfig||{},_rollbarConfig.rollbarJsUrl=_rollbarConfig.rollbarJsUrl||"https://cdnjs.cloudflare.com/ajax/libs/rollbar.js/2.3.1/rollbar.min.js",_rollbarConfig.async=void 0===_rollbarConfig.async||_rollbarConfig.async;var a=n.setupShim(window,_rollbarConfig),l=t(_rollbarConfig);window.rollbar=n.Rollbar,a.loadFull(window,document,!_rollbarConfig.async,_rollbarConfig,l)},function(r,o,e){"use strict";function n(r){return function(){try{return r.apply(this,arguments)}catch(r){try{console.error("[Rollbar]: Internal error",r)}catch(r){}}}}function t(r,o){this.options=r,this._rollbarOldOnError=null;var e=s++;this.shimId=function(){return e},window&&window._rollbarShims&&(window._rollbarShims[e]={handler:o,messages:[]})}function a(r,o){var e=o.globalAlias||"Rollbar";if("object"==typeof r[e])return r[e];r._rollbarShims={},r._rollbarWrappedError=null;var t=new p(o);return n(function(){o.captureUncaught&&(t._rollbarOldOnError=r.onerror,i.captureUncaughtExceptions(r,t,!0),i.wrapGlobals(r,t,!0)),o.captureUnhandledRejections&&i.captureUnhandledRejections(r,t,!0);var n=o.autoInstrument;return(void 0===n||n===!0||"object"==typeof n&&n.network)&&r.addEventListener&&(r.addEventListener("load",t.captureLoad.bind(t)),r.addEventListener("DOMContentLoaded",t.captureDomContentLoaded.bind(t))),r[e]=t,t})()}function l(r){return n(function(){var o=this,e=Array.prototype.slice.call(arguments,0),n={shim:o,method:r,args:e,ts:new Date};window._rollbarShims[this.shimId()].messages.push(n)})}var i=e(2),s=0,d=e(3),c=function(r,o){return new t(r,o)},p=d.bind(null,c);t.prototype.loadFull=function(r,o,e,t,a){var l=function(){var o;if(void 0===r._rollbarDidLoad){o=new Error("rollbar.js did not load");for(var e,n,t,l,i=0;e=r._rollbarShims[i++];)for(e=e.messages||[];n=e.shift();)for(t=n.args||[],i=0;i<t.length;++i)if(l=t[i],"function"==typeof l){l(o);break}}"function"==typeof a&&a(o)},i=!1,s=o.createElement("script"),d=o.getElementsByTagName("script")[0],c=d.parentNode;s.crossOrigin="",s.src=t.rollbarJsUrl,e||(s.async=!0),s.onload=s.onreadystatechange=n(function(){if(!(i||this.readyState&&"loaded"!==this.readyState&&"complete"!==this.readyState)){s.onload=s.onreadystatechange=null;try{c.removeChild(s)}catch(r){}i=!0,l()}}),c.insertBefore(s,d)},t.prototype.wrap=function(r,o,e){try{var n;if(n="function"==typeof o?o:function(){return o||{}},"function"!=typeof r)return r;if(r._isWrap)return r;if(!r._rollbar_wrapped&&(r._rollbar_wrapped=function(){e&&"function"==typeof e&&e.apply(this,arguments);try{return r.apply(this,arguments)}catch(e){var o=e;throw"string"==typeof o&&(o=new String(o)),o._rollbarContext=n()||{},o._rollbarContext._wrappedSource=r.toString(),window._rollbarWrappedError=o,o}},r._rollbar_wrapped._isWrap=!0,r.hasOwnProperty))for(var t in r)r.hasOwnProperty(t)&&(r._rollbar_wrapped[t]=r[t]);return r._rollbar_wrapped}catch(o){return r}};for(var u="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,captureDomContentLoaded,captureLoad".split(","),f=0;f<u.length;++f)t.prototype[u[f]]=l(u[f]);r.exports={setupShim:a,Rollbar:p}},function(r,o){"use strict";function e(r,o,e){if(r){var t;"function"==typeof o._rollbarOldOnError?t=o._rollbarOldOnError:r.onerror&&!r.onerror.belongsToShim&&(t=r.onerror,o._rollbarOldOnError=t);var a=function(){var e=Array.prototype.slice.call(arguments,0);n(r,o,t,e)};a.belongsToShim=e,r.onerror=a}}function n(r,o,e,n){r._rollbarWrappedError&&(n[4]||(n[4]=r._rollbarWrappedError),n[5]||(n[5]=r._rollbarWrappedError._rollbarContext),r._rollbarWrappedError=null),o.handleUncaughtException.apply(o,n),e&&e.apply(r,n)}function t(r,o,e){if(r){"function"==typeof r._rollbarURH&&r._rollbarURH.belongsToShim&&r.removeEventListener("unhandledrejection",r._rollbarURH);var n=function(r){var e=r.reason,n=r.promise,t=r.detail;!e&&t&&(e=t.reason,n=t.promise),o&&o.handleUnhandledRejection&&o.handleUnhandledRejection(e,n)};n.belongsToShim=e,r._rollbarURH=n,r.addEventListener("unhandledrejection",n)}}function a(r,o,e){if(r){var n,t,a="EventTarget,Window,Node,ApplicationCache,AudioTrackList,ChannelMergerNode,CryptoOperation,EventSource,FileReader,HTMLUnknownElement,IDBDatabase,IDBRequest,IDBTransaction,KeyOperation,MediaController,MessagePort,ModalWindow,Notification,SVGElementInstance,Screen,TextTrack,TextTrackCue,TextTrackList,WebSocket,WebSocketWorker,Worker,XMLHttpRequest,XMLHttpRequestEventTarget,XMLHttpRequestUpload".split(",");for(n=0;n<a.length;++n)t=a[n],r[t]&&r[t].prototype&&l(o,r[t].prototype,e)}}function l(r,o,e){if(o.hasOwnProperty&&o.hasOwnProperty("addEventListener")){for(var n=o.addEventListener;n._rollbarOldAdd&&n.belongsToShim;)n=n._rollbarOldAdd;var t=function(o,e,t){n.call(this,o,r.wrap(e),t)};t._rollbarOldAdd=n,t.belongsToShim=e,o.addEventListener=t;for(var a=o.removeEventListener;a._rollbarOldRemove&&a.belongsToShim;)a=a._rollbarOldRemove;var l=function(r,o,e){a.call(this,r,o&&o._rollbar_wrapped||o,e)};l._rollbarOldRemove=a,l.belongsToShim=e,o.removeEventListener=l}}r.exports={captureUncaughtExceptions:e,captureUnhandledRejections:t,wrapGlobals:a}},function(r,o){"use strict";function e(r,o){this.impl=r(o,this),this.options=o,n(e.prototype)}function n(r){for(var o=function(r){return function(){var o=Array.prototype.slice.call(arguments,0);if(this.impl[r])return this.impl[r].apply(this.impl,o)}},e="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,_createItem,wrap,loadFull,shimId,captureDomContentLoaded,captureLoad".split(","),n=0;n<e.length;n++)r[e[n]]=o(e[n])}e.prototype._swapAndProcessMessages=function(r,o){this.impl=r(this.options);for(var e,n,t;e=o.shift();)n=e.method,t=e.args,this[n]&&"function"==typeof this[n]&&("captureDomContentLoaded"===n||"captureLoad"===n?this[n].apply(this,[t[0],e.ts]):this[n].apply(this,t));return this},r.exports=e},function(r,o){"use strict";r.exports=function(r){return function(o){if(!o&&!window._rollbarInitialized){r=r||{};for(var e,n,t=r.globalAlias||"Rollbar",a=window.rollbar,l=function(r){return new a(r)},i=0;e=window._rollbarShims[i++];)n||(n=e.handler),e.handler._swapAndProcessMessages(l,e.messages);window[t]=n,window._rollbarInitialized=!0}}}}]);
     }
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-113913768-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-113913768-1');
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          displayAlign: "left",
          displayIndent: "2em"
        });
    </script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG"></script>

    
  <link rel="stylesheet" type="text/css" href="../../css/causal-graphs.css" />


</head>
<body>
<div id="underlay">
<nav><a href="../../">Home</a></nav>
<main><article>
  <h2 id="article-title">Instrumental variables on causal graphs</h2>
  
  <div class="metadata">
  <nav class="tags"><ul>
    
      <li><a href="../../tag/causality/">causality</a></li>
    
      <li><a href="../../tag/interactive/">interactive</a></li>
    
</ul></nav>

  
    <nav><a class="series" href="../../series/Graphical%2520causal%2520models/">Series: Graphical causal models</a></nav>
  
  <span class="date">Published on <time datetime="2019-06-20">June 20, 2019</time>.</span>
  
    <br><span class="date">Last edited on <time datetime="2019-06-24">June 24, 2019</time>.</span>
  
  </div>
  
  

  

  
<div class="toc"><h5>Contents</h5>
<ul>
<li><a href="#instrumental-variables">Instrumental variables</a></li>
<li><a href="#instrumental-variables-on-causal-graphs">Instrumental variables on causal graphs</a><ul>
<li><a href="#a-brief-notational-interlude">A brief notational interlude</a></li>
<li><a href="#defined">Defined</a></li>
<li><a href="#interactive">Interactive</a></li>
<li><a href="#explained">Explained</a><ul>
<li><a href="#compatible-models">Compatible models</a></li>
<li><a href="#the-instrumental-variable">The instrumental variable</a></li>
<li><a href="#d-separations">d-separations</a></li>
<li><a href="#model-selection">Model selection</a></li>
</ul></li>
<li><a href="#as-model-selection">As model selection</a></li>
</ul></li>
</ul>
</div>
<p><a href="../../posts/flip-it-reverse-it-graphical-causal-models/">Last time</a> we talked about viewing d-separation as a tool for model selection. But we’re pretty limited in the causal models we can distinguish between by only observing our variables of interest—any two graphs with the same set of d-separations are indistinguishable. <a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation">Instrumental variables</a> are a common tool for trying to get around the limitations of purely observational data.</p>
<h3 id="instrumental-variables">Instrumental variables</h3>
<p>Instrumental variables (IV) are variables that we’re not intrinsically interested in but that we look at in an attempt to suss out causality. The instrument must be correlated with our cause, but its only impact on the effect should be via the cause.</p>
<p>The classic example is about—you guessed it—smoking. Because running an RCT on smoking is ethically verboten, we’re limited to observational data. How can we determine if smoking causes lung cancer from observational data alone? An instrumental variable! To reiterate, we want a factor that affects smoking prevalence but (almost certainly) does not affect lung cancer in other ways. Finding an instrument that satisfies the <abbr title="instrumental variable">IV</abbr> criteria generally seems to require substantial creativity. Can you think of an instrument for the causal effect of smoking on lung cancer?</p>
<p>…</p>
<p>An instrument that meets these criteria is a tax on cigarettes. We expect smoking to decrease as taxes increase, but it seems hard to imagine a cigarette tax otherwise having an effect on lung cancer.</p>
<h3 id="instrumental-variables-on-causal-graphs">Instrumental variables on causal graphs</h3>
<p>Okay, so that’s what <abbr title="instrument variable">IV</abbr>s are at a high level. But what are they concretely in the graphical causal model setting we’ve been developing?</p>
<h4 id="a-brief-notational-interlude">A brief notational interlude</h4>
<p>We’ll get this out of the way here:</p>
<ul>
<li><span class="math inline">\(\perp\!\!\!\perp\)</span> is the symbol for d-separation</li>
<li>Once we add the strikethrough, <span class="math inline">\(\not\!\!{\perp\!\!\!\perp}\)</span> mean d-connected.</li>
<li>If <span class="math inline">\(G\)</span> is a graph, <span class="math inline">\(G_{\overline{X}}\)</span>, is <span class="math inline">\(G\)</span> in which <span class="noted">all the edges pointing to vertex X have been removed</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</li>
</ul>
<h4 id="defined">Defined</h4>
<p>We’ll start with the definition and then try to build up a feel for it. An instrumental variable X for the causal effect of Y on Z in graph G must be:</p>
<ol type="1">
<li>d-connected to our cause Y—<span class="math inline">\((X \not\!\!{\perp\!\!\!\perp} Y)_G\)</span></li>
<li>d-separated from our effect Z after severing the cause Y from all its parents—<span class="math inline">\((X \perp\!\!\!\perp Z)_{G_\overline{Y}}\)</span></li>
</ol>
<!--more-->
<h4 id="interactive">Interactive</h4>
<p>Below is a widget for finding instrumental variables. You can specify your graph (same format as before) in the top text area and make a query about a particular causal relationship in the input fields below the text area. The analysis will update when you defocus the inputs or text area.</p>
<p>Hopefully, you can get an intuition for what <abbr title="instrumental variable">IV</abbr>s mean graphically by generating lots of examples for yourself.</p>
<hr id="widget-hr">
<div id="spec-and-render">
<textarea id="graph-spec">
a:
  - b
  - c
b:
  - c
c:
  []
d:
  - b
</textarea>
<div id="graph-svg">

</div>
</div>
<div id="graph-error">

</div>
<div class="analysis-panel">
<div class="analysis-header">
<p>What are the instruments for the causal effect of <input id="instruments-cause" type="text" value="b" /> on <input id="instruments-effect" type="text" value="c" />?</p>
</div>
<div id="instruments-result">

</div>
</div>
<h4 id="explained">Explained</h4>
<p>Unfortunately, I think this may get a bit confusing. Our overall plan is:</p>
<ol type="1">
<li>Enumerate the models compatible with d-connection between the possible cause Y and effect Z</li>
<li>Assume that we’re right about cause and effect and add a corresponding instrumental variable</li>
<li>Calculate d-separations for the models from step 1 with the additional variable from step 2</li>
<li>Find that the d-separations now cleanly separate the model in which Y is a cause of Z from others</li>
</ol>
<h5 id="compatible-models">Compatible models</h5>
<p>How does X help us determine whether Y and Z are causally linked? We can analyze things by cases. The actual <span class="noted">path</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> being modeled must:</p>
<ol type="1">
<li>Be unidirectional from Y to Z (Y → A → … → B → Z) which means Y indeed causes Z,</li>
<li>Be unidirectional from Z to Y (Y ← A ← … ← B ← Z) which means Z actually causes Y, or</li>
<li>Have a fork between Y and Z (Y ← … ← A → … → Z) which means Y and Z are both caused by some unknown factor.</li>
<li>Not have a collider between Y and Z (Y → … → A ← … ← Z). If it did, Y and Z would be d-separated and it would have been immediately obvious from the data that there’s no causal relationship.</li>
</ol>
<h5 id="the-instrumental-variable">The instrumental variable</h5>
<p>There’s only an <abbr title="instrumental variable">IV</abbr> for the causal effect of Y on Z if Y indeed causes Z so we’ll figure out how to <span class="noted">add the <abbr title="instrumental variable">IV</abbr></span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> to the graph by looking at path 1. Our instrument X must be a parent of Y (X → Y → A → … → B → Z). If it were a child of Y (X ← Y → A → … → B → Z), it would satisfy <abbr title="instrumental variable">IV</abbr> condition 1 (d-connection to the potential cause), but it wouldn’t satisfy <abbr title="instrumental variable">IV</abbr> condition 2 because it would still be d-connected to Z even after Y removed all 0 of the edges from its parents.</p>
<p>(I suspect the above paragraph reads as very dense. The takeaway is that we want an instrumental variable on path 1 and there’s only one way to add a single vertex and edge that satisfies the two <abbr title="instrumental variable">IV</abbr> conditions. That way is for the <abbr title="instrumental variable">IV</abbr> to be a parent of the cause.)</p>
<h5 id="d-separations">d-separations</h5>
<p>Once we make this same modification—add a variable X which is a parent/cause of Y—to the other paths, we can determine whether X is truly an instrumental variable. In other words, it’s important that our instrumental variable separates case 1—where Y genuinely has a causal effect on Z—from the other two cases—where it doesn’t. Here’s what happens in each case:</p>
<ol type="1">
<li>X → Y → A → … → B → Z: Our instrument X is d-connected to the effect Z.</li>
<li>X → Y ← A ← … ← B ← Z: Our instrument X is d-separated from Z by the collider at Y.</li>
<li>X → Y ← … ← A → … → Z: Our instrument X is d-separated from Z by the collider at Y.</li>
</ol>
<h5 id="model-selection">Model selection</h5>
<p>Hurray! Our instrumental variable has done just what we wanted—used observation alone to suss out causality. If the random variable X is d-connected to the potential effect (which can be determined just from the data), the potential cause is actually a cause. If the potential instrument is d-separated from the potential effect (which can be determined just from the data), it turns out that it’s not actually an instrumental variable because the potential cause isn’t actually a cause.</p>
<h4 id="as-model-selection">As model selection</h4>
<p>Last time, we talked about d-separation as a tool for model selection. We can also think of instrumental variables in this way. Instrumental variables are just another tool in the toolbox that allow us to improve our powers of discrimination—allow us to distinguish between models that are indistinguishable when looking only at observations on variables of intrinsic interest.</p>
<p>Below, enter specifications for two causal graphs (The two graphs should contain the same set of vertices—only the edges should differ.). The resulting analysis will show you all the instruments that would allow you to distinguish between the two models with observation alone. Each row contains a different instrumental variable. The left column shows the extra variable as it would look on the graph specified in the left-hand text area while the right column shows the <abbr title="instrumental variable">IV</abbr> on the right text area’s graph. In each row, you should see that the columns have different sets of d-separations.</p>
<hr id="widget-hr">
<div id="spec1-spec2">
<textarea id="graph-spec1">
a:
  - b
  - c
b:
  []
c:
  []
</textarea>
<textarea id="graph-spec2">
a:
  []
b:
  - a
  - c
c:
  []
</textarea>
</div>
<div id="discriminate-error">

</div>
<div id="discriminate-analysis">

</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>A useful (IMO) mnemonic is to think of the overline as a knife cutting off the edges above the vertex—those from parents.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>We’ll assume there’s only one path for the sake of expository simplicity. <a href="https://www.theproofistrivial.com/">The story doesn’t really change with multiple paths</a>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>For simplicity, we’ll only look at instruments that are directly adjacent to our cause Y rather than those that are d-connected at a distance. <a href="https://www.theproofistrivial.com/">It doesn’t change the analysis materially.</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</article></main>

</div>




<script defer type="text/javascript" src="../../js/custom-elements.js"></script>

<script defer type="text/javascript" src="../../js/vendors~arg-map~custom-elements~util-egal.js"></script>


<script defer type="text/javascript" src="../../js/causal-graphs.js"></script>


  </body>
</html>
