<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.9">
    <title>Home—ColEx</title>
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,300,700,400italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="./css/default.css" />
    <link rel="icon" href="./images/favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="./images/favicon.ico" type="image/x-icon" />
    <script>
     if (!location.host.startsWith('localhost')) {
       var _rollbarConfig = {
         checkIgnore: function(isUncaught, args, payload) {
           return location.host.startsWith('localhost')
         },
         accessToken: "137e3ab64049469ba4a7d5e13a6f5aeb",
         captureUncaught: true,
         payload: {
           environment: "production"
         }
       };
       !function(r){function o(n){if(e[n])return e[n].exports;var t=e[n]={exports:{},id:n,loaded:!1};return r[n].call(t.exports,t,t.exports,o),t.loaded=!0,t.exports}var e={};return o.m=r,o.c=e,o.p="",o(0)}([function(r,o,e){"use strict";var n=e(1),t=e(4);_rollbarConfig=_rollbarConfig||{},_rollbarConfig.rollbarJsUrl=_rollbarConfig.rollbarJsUrl||"https://cdnjs.cloudflare.com/ajax/libs/rollbar.js/2.3.1/rollbar.min.js",_rollbarConfig.async=void 0===_rollbarConfig.async||_rollbarConfig.async;var a=n.setupShim(window,_rollbarConfig),l=t(_rollbarConfig);window.rollbar=n.Rollbar,a.loadFull(window,document,!_rollbarConfig.async,_rollbarConfig,l)},function(r,o,e){"use strict";function n(r){return function(){try{return r.apply(this,arguments)}catch(r){try{console.error("[Rollbar]: Internal error",r)}catch(r){}}}}function t(r,o){this.options=r,this._rollbarOldOnError=null;var e=s++;this.shimId=function(){return e},window&&window._rollbarShims&&(window._rollbarShims[e]={handler:o,messages:[]})}function a(r,o){var e=o.globalAlias||"Rollbar";if("object"==typeof r[e])return r[e];r._rollbarShims={},r._rollbarWrappedError=null;var t=new p(o);return n(function(){o.captureUncaught&&(t._rollbarOldOnError=r.onerror,i.captureUncaughtExceptions(r,t,!0),i.wrapGlobals(r,t,!0)),o.captureUnhandledRejections&&i.captureUnhandledRejections(r,t,!0);var n=o.autoInstrument;return(void 0===n||n===!0||"object"==typeof n&&n.network)&&r.addEventListener&&(r.addEventListener("load",t.captureLoad.bind(t)),r.addEventListener("DOMContentLoaded",t.captureDomContentLoaded.bind(t))),r[e]=t,t})()}function l(r){return n(function(){var o=this,e=Array.prototype.slice.call(arguments,0),n={shim:o,method:r,args:e,ts:new Date};window._rollbarShims[this.shimId()].messages.push(n)})}var i=e(2),s=0,d=e(3),c=function(r,o){return new t(r,o)},p=d.bind(null,c);t.prototype.loadFull=function(r,o,e,t,a){var l=function(){var o;if(void 0===r._rollbarDidLoad){o=new Error("rollbar.js did not load");for(var e,n,t,l,i=0;e=r._rollbarShims[i++];)for(e=e.messages||[];n=e.shift();)for(t=n.args||[],i=0;i<t.length;++i)if(l=t[i],"function"==typeof l){l(o);break}}"function"==typeof a&&a(o)},i=!1,s=o.createElement("script"),d=o.getElementsByTagName("script")[0],c=d.parentNode;s.crossOrigin="",s.src=t.rollbarJsUrl,e||(s.async=!0),s.onload=s.onreadystatechange=n(function(){if(!(i||this.readyState&&"loaded"!==this.readyState&&"complete"!==this.readyState)){s.onload=s.onreadystatechange=null;try{c.removeChild(s)}catch(r){}i=!0,l()}}),c.insertBefore(s,d)},t.prototype.wrap=function(r,o,e){try{var n;if(n="function"==typeof o?o:function(){return o||{}},"function"!=typeof r)return r;if(r._isWrap)return r;if(!r._rollbar_wrapped&&(r._rollbar_wrapped=function(){e&&"function"==typeof e&&e.apply(this,arguments);try{return r.apply(this,arguments)}catch(e){var o=e;throw"string"==typeof o&&(o=new String(o)),o._rollbarContext=n()||{},o._rollbarContext._wrappedSource=r.toString(),window._rollbarWrappedError=o,o}},r._rollbar_wrapped._isWrap=!0,r.hasOwnProperty))for(var t in r)r.hasOwnProperty(t)&&(r._rollbar_wrapped[t]=r[t]);return r._rollbar_wrapped}catch(o){return r}};for(var u="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,captureDomContentLoaded,captureLoad".split(","),f=0;f<u.length;++f)t.prototype[u[f]]=l(u[f]);r.exports={setupShim:a,Rollbar:p}},function(r,o){"use strict";function e(r,o,e){if(r){var t;"function"==typeof o._rollbarOldOnError?t=o._rollbarOldOnError:r.onerror&&!r.onerror.belongsToShim&&(t=r.onerror,o._rollbarOldOnError=t);var a=function(){var e=Array.prototype.slice.call(arguments,0);n(r,o,t,e)};a.belongsToShim=e,r.onerror=a}}function n(r,o,e,n){r._rollbarWrappedError&&(n[4]||(n[4]=r._rollbarWrappedError),n[5]||(n[5]=r._rollbarWrappedError._rollbarContext),r._rollbarWrappedError=null),o.handleUncaughtException.apply(o,n),e&&e.apply(r,n)}function t(r,o,e){if(r){"function"==typeof r._rollbarURH&&r._rollbarURH.belongsToShim&&r.removeEventListener("unhandledrejection",r._rollbarURH);var n=function(r){var e=r.reason,n=r.promise,t=r.detail;!e&&t&&(e=t.reason,n=t.promise),o&&o.handleUnhandledRejection&&o.handleUnhandledRejection(e,n)};n.belongsToShim=e,r._rollbarURH=n,r.addEventListener("unhandledrejection",n)}}function a(r,o,e){if(r){var n,t,a="EventTarget,Window,Node,ApplicationCache,AudioTrackList,ChannelMergerNode,CryptoOperation,EventSource,FileReader,HTMLUnknownElement,IDBDatabase,IDBRequest,IDBTransaction,KeyOperation,MediaController,MessagePort,ModalWindow,Notification,SVGElementInstance,Screen,TextTrack,TextTrackCue,TextTrackList,WebSocket,WebSocketWorker,Worker,XMLHttpRequest,XMLHttpRequestEventTarget,XMLHttpRequestUpload".split(",");for(n=0;n<a.length;++n)t=a[n],r[t]&&r[t].prototype&&l(o,r[t].prototype,e)}}function l(r,o,e){if(o.hasOwnProperty&&o.hasOwnProperty("addEventListener")){for(var n=o.addEventListener;n._rollbarOldAdd&&n.belongsToShim;)n=n._rollbarOldAdd;var t=function(o,e,t){n.call(this,o,r.wrap(e),t)};t._rollbarOldAdd=n,t.belongsToShim=e,o.addEventListener=t;for(var a=o.removeEventListener;a._rollbarOldRemove&&a.belongsToShim;)a=a._rollbarOldRemove;var l=function(r,o,e){a.call(this,r,o&&o._rollbar_wrapped||o,e)};l._rollbarOldRemove=a,l.belongsToShim=e,o.removeEventListener=l}}r.exports={captureUncaughtExceptions:e,captureUnhandledRejections:t,wrapGlobals:a}},function(r,o){"use strict";function e(r,o){this.impl=r(o,this),this.options=o,n(e.prototype)}function n(r){for(var o=function(r){return function(){var o=Array.prototype.slice.call(arguments,0);if(this.impl[r])return this.impl[r].apply(this.impl,o)}},e="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,_createItem,wrap,loadFull,shimId,captureDomContentLoaded,captureLoad".split(","),n=0;n<e.length;n++)r[e[n]]=o(e[n])}e.prototype._swapAndProcessMessages=function(r,o){this.impl=r(this.options);for(var e,n,t;e=o.shift();)n=e.method,t=e.args,this[n]&&"function"==typeof this[n]&&("captureDomContentLoaded"===n||"captureLoad"===n?this[n].apply(this,[t[0],e.ts]):this[n].apply(this,t));return this},r.exports=e},function(r,o){"use strict";r.exports=function(r){return function(o){if(!o&&!window._rollbarInitialized){r=r||{};for(var e,n,t=r.globalAlias||"Rollbar",a=window.rollbar,l=function(r){return new a(r)},i=0;e=window._rollbarShims[i++];)n||(n=e.handler),e.handler._swapAndProcessMessages(l,e.messages);window[t]=n,window._rollbarInitialized=!0}}}}]);
     }
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-113913768-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-113913768-1');
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          displayAlign: "left",
          displayIndent: "2em"
        });
    </script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG"></script>

    <script type="text/javascript">
if (/Trident/.test(navigator.userAgent)) {
  alert('I have reports that certain features are broken on Internet Explorer ' +
        '(e.g. SVG paths with markers, flexbox with the \'order\' attribute). ' +
        'This is a "Won\'t fix" at the moment so, if you\'re using IE, ' +
        'browse at your own risk.');
}
</script>
</head>
<body>
<div id="underlay">
<main><ul class="teasers">
  
    <li><article class="teaser">
        <h2><a href="./posts/exemplars-curse-now-with-more-math/">Exemplar's curse—Now with 80% more math!</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/decision%2520theory/">decision theory</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="July  6, 2018">July  6, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>We recently described the exemplar’s curse in words. Now we describe it with math and an interactive calculator. We also rebut one possible retort: exemplar’s curse scenarios don’t just mean we were too optimistic; they also lead us to picking the wrong exemplar.</p></div>
       

        <h3 id="intro">Intro</h3>
<p><a href="./posts/exemplars-curse-singapore/">Last time</a>, I outlined the exemplar’s curse in the context of Singapore with a parable and an informal description. Rest easy; I’ve heard your needful clamoring—I’ll now describe the curse more precisely with math.</p>
<h3 id="the-exemplars-curse">The exemplar’s curse</h3>
<p>Restating the core idea in words: The exemplar’s curse occurs when we select an exemplar from a set of outcomes which resulted from both stochastic and deterministic factors. If many outcomes have similarly compelling deterministic factors, the chosen winner is probably unusually lucky. Reversion to the mean then suggests that the chosen winner will disappoint when the deterministic factors are replicated.</p>
<h4 id="model">Model</h4>
<p>We can model this with the use of <a href="https://en.wikipedia.org/wiki/Random_variable">random variables</a>. We’ll call our bundle of deterministic factors <span class="math inline">\(\mathcal{D}\)</span> and say they range uniformly in cumulative value from <span class="math inline">\(0\)</span> to <span class="math inline">\(D\)</span> where <span class="math inline">\(D\)</span> is finite. Our bundle of stochastic factors <span class="math inline">\(\mathcal{S}\)</span> range uniformly in value from from <span class="math inline">\(0\)</span> to <span class="math inline">\(S\)</span> where <span class="math inline">\(S\)</span> is finite. Since we observe only visible outcomes rather than underlying causal factors, we see <span class="math inline">\(\mathcal{O} = \mathcal{D} + \mathcal{S}\)</span>. The exemplar’s curse is then about the inferrable properties of the causal factors <span class="math inline">\(\mathcal{D}\)</span> corresponding to the selected maximum <span class="math inline">\(\mathcal{O}\)</span> from a set of outcomes <span class="math inline">\(\mathbb{O}\)</span>.</p>
<h3 id="false-exemplars">False exemplars</h3>
<p>In the last post, we only went so far as to claim that we should expect replicating causal factors to produce disappointing outcomes due to reversion to the mean. That is, the stochastic factors <span class="math inline">\(\mathcal{S}_1\)</span> for the maximum outcome <span class="math inline">\(\mathcal{O}_1 = \max \mathbb{O}\)</span> are likely better than average (<span class="math inline">\(\frac{S}{2}\)</span>). If we generate a new outcome <span class="math inline">\(\mathcal{O}_2\)</span> using the same deterministic factors <span class="math inline">\(\mathcal{D}\)</span> that served us well in <span class="math inline">\(\mathcal{O}_1\)</span>, we should expect our new stochastic factors to be worse <span class="math inline">\(\mathcal{S}_2 &lt; \mathcal{S}_1\)</span> and so we should expect <span class="math inline">\(\mathcal{O}_2 &lt; \mathcal{O}_1\)</span>.</p>
<p>This leaves a open a compelling retort. One could say, “Even though I’m too optimistic about the eventual outcome, in selecting the exemplar, I’m still selecting the best deterministic factors. That means I’m still making the best choice I can so no harm done.”</p>
<p>Alas, this is not true. Depending on the parameters, there could be only a vanishingly small chance that the bundle of deterministic factors corresponding to the best outcome (the sum of the deterministic and stochastic factors) is also the best bundle of deterministic factors when looking <em>only</em> at the deterministic factors. In symbols, supposing we have a projection function <span class="math inline">\(p_\mathcal{D} : \mathbb{O} \rightarrow \mathbb{D}\)</span> which finds the bundle of deterministic factors <span class="math inline">\(\mathcal{D}\)</span> used in outcome <span class="math inline">\(\mathcal{O}\)</span>, we’re interested in <span class="math inline">\(P(\max \mathbb{D} = p_\mathcal{D}(\max \mathbb{O}))\)</span>.</p>
<p>For example, if we choose the max from 1000 outcomes and the value of stochastic factors ranges from 0 to 100 while the value of deterministic factors ranges from 0 to 1, we should actually be quite surprised if our best outcome actually has the best deterministic factors.</p>
<h3 id="calculator">Calculator</h3>
<p>We can help build up an intuition around this math using the calculator below. The calculator uses <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo methods</a> to estimate the probability that the maximum outcome corresponds to the maximum bundle of deterministic factors.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/exemplars-curse-singapore/">The Exemplar's Curse and Singapore</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/decision%2520theory/">decision theory</a></li>
    
      <li><a href="./tag/development/">development</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/The%2520Singapore%2520Story/">Series: The Singapore Story</a></nav>
        
        <span class="date">Published on <time datetime="July  3, 2018">July  3, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>Like the optimizer’s curse, if we try to make policy decisions based on exemplars, we may systematically mislead ourselves by picking the luckiest polities rather than the wisest. This theory might apply to Singapore.</p></div>
       

        <h3 id="the-exemplars-curse">The exemplar’s curse</h3>
<h4 id="a-parable">A parable</h4>
<p>Suppose you walk into the nearest WalMart, get on the PA, and ask everyone to congregate in the attached warehouse. Once the congregation has settled, you reveal a ream of printer paper, ask everyone to fold their best paper airplane, and finally ask everyone to toss their planes as far as they can. Once everyone’s tossed, you pull out your handy-dandy tape measure and determine which plane flew the farthest.</p>
<p>So far, so good. However, if you then proceed to marvel at the winning plane and attribute its long flight to the artful pattern of creases, you’re likely to err. Because, of course, there’s a substantial element of luck (meant in a casual sense; let’s not careen off on a tangent about determinism) in the outcome of the contest—it’s not a pure contest of skill. And in choosing the extreme value (the winner), we’ve positively selected for luck. This means our winner will likely have better than average luck. This result—in contests where many contestants are skilled, the outcome is often determined by luck—goes by the name <a href="http://mutualfunds.com/education/alpha-and-the-paradox-of-skill/">the paradox of skill</a>.</p>
<p>The unfortunate conclusion to this parable is that we should expect planes modeled after our winner to do worse than the original. Because the winner was unusually lucky, subsequent flights will experience <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean">reversion to the mean</a> and perform worse.</p>
<p>Or, another route to this intuition: Even if you ran the contest again with the exact same planes, a different pattern of air drafts, a different incidental flick of the wrist might well result in a different victor. It’s only after we’ve run many trials and looked at the pattern of results for each plane that we can bring the risk of a false victor down to acceptable levels. If luck is a significant factor and there are many contestants, chances are that this true, final victor is not the same as the plane that happened to win the first trial. This is why sporting events often have multiple matches in a series—to diminish the impact of luck and suss out skill.</p>
<h4 id="abstracted">Abstracted</h4>
<p>Summarizing, the exemplar’s curse occurs when you’re selecting an exemplar from a set of outcomes which resulted from both stochastic and deterministic factors. If many outcomes have <span class="noted">similarly compelling deterministic factors</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, the chosen winner is probably unusually lucky. Reversion to the mean then suggests that the chosen winner will disappoint when the deterministic factors are replicated.</p>
<h4 id="optimizers-curse">Optimizer’s curse</h4>
<p>The following is offered as an extra in case it helps. If it doesn’t, dismiss it with prejudice:</p>
<p>The perspicacious reader will have noticed that this is just the optimizer’s curse dressed up in causal clothes <span class="citation" data-cites="smith2006">(Smith and Winkler <a href="#ref-smith2006">2006</a>)</span>. The paradigmatic optimizer’s curse warns about the difficulty of selecting actions based on the predicted value of the action. In such circumstances, naive optimizer’s will likely be disappointed because they will systematically pick actions based on overoptimistic predictions. (If this explanation doesn’t do it for you, you can just read the beginning of the linked paper; it’s not bad.) Our exemplar’s curse is structurally similar—we just have uncertain causal inference about the past instead of uncertain predictions about the future.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/is-development-easy/">Is development easy? <i>The Singapore Story</i></a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/development/">development</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/The%2520Singapore%2520Story/">Series: The Singapore Story</a></nav>
        
        <span class="date">Published on <time datetime="July  2, 2018">July  2, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>Lee Kuan Yew’s memoir, <i>The Singapore Story</i>, makes economic development sound easy. It’s probably not. How do we explain the discrepancy?</p></div>
       

        <h3 id="singapores-economy-grew.-a-lot.">Singapore’s economy grew. A lot.</h3>
<p>It’s pretty hard to argue with the claim that <a href="https://en.wikipedia.org/wiki/Singapore">Singapore</a>’s post-independence economic development is an astounding success. <i>Per capita</i> <a href="https://en.wikipedia.org/wiki/Gross_domestic_product">GDP</a> in the country grew from $6,506 (inflation-adjusted 2010 USD) in 1970 (57th among all countries) to $46,569 in 2010 (18th among all countries) <span class="citation" data-cites="gdp_per_capita_singapore">(“Constant GDP Per Capita for Singapore”)</span> <span class="citation" data-cites="gdp_per_capita_table">(“List of Countries by Past and Projected GDP (Nominal) Per Capita” <a href="#ref-gdp_per_capita_table">2018</a>)</span>. This represents an average annual <a href="https://en.wikipedia.org/wiki/Real_versus_nominal_value_(economics)">real</a> growth rate of 5.04% <span id="singapore-gdp" class="spark"></span>. For comparison, the real growth rates of China and the US over the same period of time were <span class="noted">7.78%</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> <span id="china-gdp" class="spark"></span> and 1.84% <span id="us-gdp" class="spark"></span> respectively <span class="citation" data-cites="gdp_per_capita_china">(“Constant GDP Per Capita for China”)</span> <span class="citation" data-cites="gdp_per_capita_usa">(“Constant GDP Per Capita for the United States”)</span>.</p>
<p>Alas, broader measures of progress over that time period aren’t readily available. The UN’s <a href="http://hdr.undp.org/en/content/human-development-index-hdi">Human Development Index</a>, for example, only goes back to 1990. Thus, for want of a better measure, we’ll have to rely on GDP to support our claim that things really did change radically in Singapore after independence.</p>
<h3 id="whats-so-hard-about-growth-just-stop-making-bad-decisions-and-start-making-good-ones.">What’s so hard about growth? Just stop making bad decisions and start making good ones.</h3>
<p>A book club I recently attended read <a href="https://en.wikipedia.org/wiki/Lee_Kuan_Yew">Lee Kuan Yew’s</a> (the prime minister of Singapore from independence in 1965 to 1990) memoir, <i>The Singapore Story</i> <span class="citation" data-cites="yew2012">(Yew <a href="#ref-yew2012">2012</a>)</span>. My friend’s first reaction to the book was, “He makes it sound so easy!”, and I can’t disagree. My overwhelming impression of the book is that of proficient nonchalance.</p>
<p>Some examples from the text which I hope convey that feeling:</p>
<blockquote>
I had many pressing concerns: first, to get international recognition for Singapore’s independence, including our membership of the United Nations. I chose Sinnathamby Rajaratnam (affectionately called Raja by all of us) as foreign minister. […] He was to be much liked and respected by all those he worked with at home and abroad. As messages of recognition flowed in, Toh Chin Chye, the deputy prime minister, and Raja as foreign minister set off to New York to take our seat at the UN that September of 1965.
</blockquote>
<blockquote>
<p>Mordecai Kidron, the Israeli ambassador in Bangkok […] had approached me several times in 1962–63 to ask for an Israeli consulate in Singapore. […] I replied that it … [might] create an issue that would excite the Malay Muslim grassroots and upset my plans […].</p>
<p>[…]</p>
[N]ow that the Israeli presence in Singapore was well-known, we allowed them a diplomatic mission. They wanted an embassy. We decided to allow them a trade representative office first, in October 1968. The following May, after Malay Muslims in Singapore and the region had become accustomed to an Israeli presence, we allowed them to upgrade it to an embassy.
</blockquote>
<blockquote>
Seah Mui Kok, a union leader and PAP MP, another old friend from my time with the unions, objected to the wide latitude given to employers to hire and fire, but accepted the need for unions to be less confrontational to create a better climate for foreign investments. I included safeguards against misuse of these powers.
</blockquote>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/assorted-links-v/">Assorted links V</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/links/">links</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="June 24, 2018">June 24, 2018</time>.</span>
       </div>

       

        <ol type="1">
<li><p><a href="https://blog.acolyer.org/2018/03/30/the-surprising-creativity-of-digital-evolution/">The surprising creativity of digital evolution</a></p>
<p><img src="./images/digital-evolution-resized.jpg" alt="Exploiting potential energy to locomote" /> </p>
<blockquote>
when you give a computer system a goal, and freedom in how it achieves that goal, then be prepared for surprises in the strategies it comes up with! Some surprises are pleasant (as in ‘oh that’s clever’), but some surprises show the system going outside the bounds of what you intended (but forgot to specify, because you never realised this could be a possibility…) using any means at its disposal to maximise the given objective.
</blockquote>
<p>The analogy to human systems is left to the imagination of the reader.</p></li>
<li><p><a href="http://sootyempiric.blogspot.com/2018/06/empiricism-is-standpoint-epistemology.html">Empiricism is standpoint epistemology</a></p>
<blockquote>
Feminist standpoint theorists make three principal claims: (1) Knowledge is socially situated. (2) Marginalized groups are socially situated in ways that make it more possible for them to be aware of things and ask questions than it is for the non-marginalized. (3) Research, particularly that focused on power relations, should begin with the lives of the marginalized.
</blockquote>
<p>I have a definite soft spot for efforts to translate claims from one paradigm to another.</p></li>
<li><p><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0152719">Statistically Controlling for Confounding Constructs Is Harder than You Think</a></p>
<blockquote>
<p>Suppose we are given city statistics covering a four-month summer period, and observe that swimming pool deaths tend to increase on days when more ice cream is sold. As astute analysts, we immediately identify average daily temperature as a confound: on hotter days, people are more likely to both buy ice cream and visit swimming pools. Using multiple regression, we can statistically control for this confound, thereby eliminating the direct relationship between ice cream sales and swimming pool deaths.</p>
Now consider the following twist. Rather than directly observing recorded daily temperatures, suppose we obtain self-reported Likert ratings of subjectively perceived heat levels. […] Fig 2 illustrates what happens when the error-laden subjective heat ratings are used in place of the more precisely recorded daily temperatures. […] When controlling for the subjective heat ratings (Fig 2B), the partial correlation between ice cream sales and swimming pool deaths is smaller, but remains positive and statistically significant, r(118) = .33, p &lt; .001. Is the conclusion warranted that ice cream sales are a useful predictor of swimming pool deaths, over and above daily temperature? Obviously not. The problem is that subjective heat ratings are a noisy proxy for physical temperature, so controlling for the former does not equate observations on the latter.
</blockquote></li>
<li><p><a href="http://blog.practicalethics.ox.ac.uk/2018/02/the-psychology-of-speciesism-how-we-privilege-certain-animals-over-others/">The Psychology of Speciesism: How We Privilege Certain Animals Over Others</a></p>
<p>The post title oversells it a bit IMO, but still interesting preliminary findings:</p>
<blockquote>
<p>[W]e developed a Speciesism Scale: a standardised, validated, and reliable measurement instrument that can assess the extent to which a person has speciesist views.</p>
Speciesism correlates positively with racism, sexism, and homophobia, and seems to be underpinned by the same socio-ideological beliefs. Similar to racism and sexism, speciesism appears to be an expression of Social Dominance Orientation: the ideological belief that inequality can be justified and that weaker groups should be dominated by stronger groups […]. In addition, speciesism correlates negatively with both empathy and actively open-minded thinking. Men are more likely to be speciesists than women. Yet, there are no correlations with age or education.
</blockquote></li>
<li><p><a href="https://en.wikipedia.org/wiki/Agnotology">Agnotology</a></p>
<p>Agnotology is the study of culturally induced ignorance or doubt. The tobacco industry is an easy example. <a href="http://www.kevinhabits.com/doubt-is-our-product-fascinating-memo-on-the-tobacco-industrys-pr-strategy/">“Doubt is our product”</a>, says one industry memo.</p></li>
</ol>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/ideal-theory-shadow-realm/">Ideal theory in the shadow realm</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/ideal%2520theory/">ideal theory</a></li>
    
      <li><a href="./tag/political%2520philosophy/">political philosophy</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/The%2520Tyranny%2520of%2520the%2520Ideal/">Series: The Tyranny of the Ideal</a></nav>
        
        <span class="date">Published on <time datetime="June 21, 2018">June 21, 2018</time>.</span>
       </div>

       

        <p>It’s opposite day! Instead of talking about the ideal, we’re going to talk about the anti-ideal—the worst of all possible worlds. I contend that, if ideal theory is useful, anti-ideal theory is also useful.</p>
<p><a href="./posts/ideal-calibration/">Last time</a>, we covered two roles for ideal theory—ideal as destination and ideal as calibration. We’ll examine the anti-ideal from each perspective.</p>
<h3 id="ideal-as-destination">Ideal as destination</h3>
<p>To recapitulate, this line of thinking claims the ideal is useful because it provides a long-term goal and something to work toward. Symmetrically, the anti-ideal is useful because it provides a long-term anti-goal and something to avoid. We operationalize this as seeking to minimize the distance between our current world and the ideal and maximize the distance between our world and the anti-ideal.</p>
<p>This is where the symmetry breaks down. For most reasonable <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a>, there is only one world with a minimum distance to the ideal—namely, the ideal itself. Depending on what we believe about the set of possible worlds, there might be none, one or many points which are at a maximum distance from the anti-ideal.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/ideal-calibration/">Ideal theory as calibration</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/ideal%2520theory/">ideal theory</a></li>
    
      <li><a href="./tag/political%2520philosophy/">political philosophy</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/The%2520Tyranny%2520of%2520the%2520Ideal/">Series: The Tyranny of the Ideal</a></nav>
        
        <span class="date">Published on <time datetime="June 20, 2018">June 20, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>The ideal serves not only as destination but as calibration. Once we acknowledge our ignorance of possible worlds, we must treat the task of social engineering as a problem of statistical inference. From the statistical inference perspective, the ideal (maximum) is very informative about the underlying distribution of possible worlds and helps us make more informed trade-offs.</p></div>
       

        <div class="macros">

</div>
<h3 id="intro">Intro</h3>
<p><a href="./posts/utopia-infinitude-secretaries/">Last time</a>, I described how <span class="citation" data-cites="gaus2016">(Gaus <a href="#ref-gaus2016">2016</a>)</span> juxtaposes unidimensional and multidimensional models of justice. I went on to contest the claim that the ideal is otiose in the unidimensional model and made an analogy to <a href="https://en.wikipedia.org/wiki/Secretary_problem">the secretary problem</a>.</p>
<p>This time I’ll make the (related) argument directly that there are two distinct uses of ideal theorizing and only one is bad from the unidimensional perspective.</p>
<h3 id="dimensionality-of-justice">Dimensionality of justice</h3>
<p>Let’s try to formalize ‘unidimensional’ and ‘multidimensional’ models of justice so we can be sure we’re thinking of the same thing. Gaus suggests (and I’ll accept) that a key part of any theory of ideal justice includes a function <span class="noted"><span class="math inline">\(e \colon \mathbb{W} \to \mathbb{R}\)</span></span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, a set of possible worlds <span class="math inline">\(\mathbb{W}\)</span>. In other words, each such theory should be able to assign a ‘justice score’ to every possible world. In terms of this machinery, the unidimensional model simply limits itself to using <em>only</em> <span class="math inline">\(e\)</span> and <span class="math inline">\(\mathbb{W}\)</span>. The multidimensional model on the other hand also gives us a tool to inspect the structure of <span class="math inline">\(\mathbb{W}\)</span> in the form of a <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> <span class="math inline">\(d \colon \mathbb{W} \times \mathbb{W} \to [0,\inf)\)</span>. In other words, the multidimensional model lets us determine how similar two possible worlds are in some way that’s not directly related to their justice scores.</p>
<p>To actually use this in a model, we’ll also need a way of finding worlds <span class="math inline">\(W\)</span> from <span class="math inline">\(\mathbb{W}\)</span> to evaluate. We denote a a random, ‘nearby’ (i.e. one with a small distance <span class="math inline">\(d(W, W_c)\)</span> from the then-current world <span class="math inline">\(W_c\)</span>) world as <span class="math inline">\(W_r\)</span>.</p>
<h3 id="ideal-as-destination">Ideal as destination</h3>
<p><span class="citation" data-cites="gaus2016">(Gaus <a href="#ref-gaus2016">2016</a>)</span> and the rest of the literature suggest that the an ideal is useful as a destination. According to Rawls, “By showing how the social world may realize the features of a realistic Utopia, political philosophy provides a long-term goal of political endeavor, and in working toward it gives meaning to what we can do today.” <span class="citation" data-cites="rawls1993">(Rawls <a href="#ref-rawls1993">1993</a>)</span></p>
<p>In terms of our model, the ideal is <span class="math inline">\(\mathop{\mathrm{argmax}}\limits_{W \in \mathbb{W}} e(W) = W_i\)</span>, the possible world that achieves the highest justice score. A wholly naive algorithm would then:</p>
<ol type="1">
<li>Use our ideal <span class="math inline">\(W_i\)</span> to orient societal progress by always picking <span class="math inline">\(\mathop{\mathrm{argmin}}\limits_{W \in \{W_c, W_r\}} d(W, W_i) = W_{bk}\)</span>. In other words, on every ‘step’, someone proposes some random alternative world <span class="math inline">\(W_r\)</span> and this naive algorithm compares it to the current world and picks whichever is closer to the ideal.</li>
<li>Stop when <span class="math inline">\(d(W_c, W_i) = 0\)</span>.</li>
</ol>
<p>With this interpretation, it’s clear that the ideal as destination as not only otiose in the unidimensional model but nonsensical. The unidimensional perspective was defined by its omission of the metric <span class="math inline">\(d\)</span> so we certainly can’t use it in our algorithm to find <span class="math inline">\(W_{bk}\)</span>.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/utopia-infinitude-secretaries/">Utopia and an infinitude of secretaries</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/ideal%2520theory/">ideal theory</a></li>
    
      <li><a href="./tag/political%2520philosophy/">political philosophy</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/The%2520Tyranny%2520of%2520the%2520Ideal/">Series: The Tyranny of the Ideal</a></nav>
        
        <span class="date">Published on <time datetime="June 19, 2018">June 19, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p><i>The Tyranny of the Ideal</i> juxtaposes a unidimensional model of worlds with a multidimensional model. It goes on to suggest that ideal theory is otiose in the unidimensional model. I disagree and attempt to illustrate the disagreement via analogy to the famous secretary problem.</p></div>
       

        <h3 id="ideals-as-superfluous">Ideals as superfluous</h3>
<p>In <span class="citation" data-cites="gaus2016">(Gaus <a href="#ref-gaus2016">2016</a>)</span>, the author lays out two conflicting views of social engineering. The <a href="https://plato.stanford.edu/entries/rawls/#IdeNonIdeThe">ideal theorists</a> insist on the value of having an ideal society in mind when deciding between possible futures. Their opponents, represented by <a href="https://en.wikipedia.org/wiki/Amartya_Sen">Amartya Sen</a>, suggest this is a bit silly.</p>
<blockquote>
The possibility of having an identifiably perfect alternative does not indicate that it is necessary, or indeed useful, to refer to it in judging the relative merits of two alternatives; for example, we may be willing to accept, with great certainty, that Mount Everest is the tallest mountain in the world, completely unbeatable in terms of stature by any other peak, but that understanding is neither needed, nor particularly helpful, in comparing the peak heights of, say, Mount Kilimanjaro and Mount McKinley. There would be something off in the general belief that a comparison of any two alternatives cannot be sensibly made without a prior identification of a supreme alternative. <span class="attribution"><span class="citation" data-cites="sen2011">(Sen <a href="#ref-sen2011">2011</a>)</span></span>
</blockquote>
<p>(The mountain climbing metaphor is popular in discussions of ideal theory.)</p>
<p>Gaus goes on to characterize Sen’s perspective as fundamentally unidimensional. He concludes the discussion with the following, “In this book, then, I shall explore multidimensional ways of thinking about justice, for they provide the most compelling response to Sen’s elegant unidimensional analysis—an analysis that makes the ideal otiose.”</p>
<h3 id="counterclaim">Counterclaim</h3>
<p>But I, random Internet blogger, claim they are both wrong. Or, at a minimum, very misleading. The ideal serves a role even from the unidimensional perspective.</p>
<p>Implicitly, they are both modeling the unidimensional search for a better world as one across a known set of worlds with a <a href="https://en.wikipedia.org/wiki/Well-order">well-order</a> guiding the way. But this assumes too much. Even if we (unrealistically) suppose we can flawlessly evaluate each world or pair of worlds, we do not know the full set of possible worlds. Rather than perfect information, we are in a state of relative ignorance, groping in the dark. Given our ignorance, any information about the distribution of possible worlds (including the maximum—the ideal) is valuable.</p>
<h4 id="secretary-problem">Secretary problem</h4>
<p>To see that distributional information is valuable even in a unidimensional context, we’ll model ideal theory as a classic unidimensional problem: <a href="https://en.wikipedia.org/wiki/Secretary_problem">the secretary problem</a>. In this problem, an employer wants to hire a secretary and starts to interview applicants. After each interview, the employer can decide to continue interviewing or hire the last interviewee and end the process. Their goal is to stop optimally so that they hire the best possible applicant.</p>
<p>The crucial consideration for us is that the employer doesn’t know in advance the quality of the best secretary in the applicant pool. After each interview, the employer must decide if this is as good as it gets or whether to gamble by continuing on. If the employer knew in advance what the best applicant looked like, the problem would be trivial—just keep interviewing until you reach the best applicant.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/how-not-write-book/">How not to write a book</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/reading/">reading</a></li>
    
      <li><a href="./tag/meta%2520monday/">meta monday</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="June 18, 2018">June 18, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p><em>How to Read a Book</em> was a pretty big waste of time for me. It probably would be for you too.</p></div>
       

        <h3 id="intro">Intro</h3>
<div class="skippable">
<blockquote>
Multiple-choice questions are in turn of many kinds; usually they are presented in homogeneous groups. Sometimes a series of statements follows the reading exercise, and the person being tested is asked to indicate which statement best expresses the main idea or ideas of the passage read. In other cases the reader may be offered a choice of statements about a detail in the text, only one of which is a valid interpretation of the text, or at least is more apt than the others; or it may be the other way around; one is an incorrect choice, and the others are correct. Or a verbatim quotation may be given from the text to discover whether the reader has taken note of it and remembered it. Sometimes, in a statement either quoted directly or simply drawn from the text the reader will find a blank indicating that one or more words that will make sense of the statement have been omitted. Then follows a list of choices, lettered or numbered, among which the person being tested is asked to choose the phrase that, when inserted in the blank, best completes the statement.
</blockquote>
</div>
<p>Yes, that’s 200 words explaining what multiple-choice questions are. If you’d like 426 more pages of mildly condescending prose explaining the obvious, boy, do I have a book for you. Mortimer J. Adler’s <a href="https://en.wikipedia.org/wiki/How_to_Read_a_Book"><em>How to Read a Book</em></a> is saved from the appellation ‘worst publication of 1940’ only due to stiff competition from <a href="https://en.wikipedia.org/wiki/Three_Whom_God_Should_Not_Have_Created:_Persians,_Jews,_and_Flies">Ba’ath propagandists</a>.</p>


    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/deposition-schemes/">Deposition schemes</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/political%2520economy/">political economy</a></li>
    
      <li><a href="./tag/autocracy/">autocracy</a></li>
    
      <li><a href="./tag/constructive/">constructive</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/Why%2520Nations%2520Fail/">Series: Why Nations Fail</a></nav>
        
        <span class="date">Published on <time datetime="June 15, 2018">June 15, 2018</time>.</span>
       </div>

       
         <div class="abstract"><p>We’ve spent a lot of time recently talking about Acemoglu and Robinson’s work—in particular, about autocrats. Now, we’ll try to turn our new understanding to constructive ends. The first scheme is for an international organization to facilitate abdication by organizing and enforcing retirement payments for dictators. The second scheme is for the ICC to offer abdication ‘credits’ that reduce the severity of criminal punishment for autocrats in the event of voluntary abdication.</p></div>
       

        <p>We’ve been talking about autocrats lately. It’d be good if we could put our new understanding to use. In that spirit, here are a couple of constructive schemes.</p>
<h3 id="retirement-plans">Retirement plans</h3>
<h4 id="the-problem">The problem</h4>
<p><span class="citation" data-cites="acemoglu2005">(Acemoglu, Johnson, and Robinson <a href="#ref-acemoglu2005">2005</a>)</span> describe the difficulties an autocracy faces in the voluntary relinquishment of power:</p>
<blockquote>
A similar problem plagues the reverse solution, whereby the dictator agrees to a voluntary transition to democracy in return for some transfers in the future to compensate him for the lost income and privileges. Those who will benefit from a transition to democracy would be willing to make such promises, but once the dictator relinquishes his political power, there is no guarantee that citizens would agree to tax themselves in order to make payments to this former dictator. Promises of compensation to a former dictator are typically not credible.
</blockquote>
<h4 id="a-solution">A solution</h4>
<p>If, as proposed in <a href="./posts/mo-money-mo-problems-autocrat-remix/">the previous post</a>, autocrats would prefer a guarantee of somewhat reduced income to a chance of somewhat greater income, this transition would be a Pareto improvement. The autocrat gets stability and in exchange the people suffer less expropriation/taxation. So indeed, the only problem is one of commitment.</p>
<p>We can solve this problem by moving ‘up a level’. The citizens of any particular country can’t credibly commit to honoring such an agreement. But if we turn the one-shot game into an repeated game by asking an international organization (e.g. the UN) to facilitate and enforce all such agreements, we create a new equilibrium. The UN (or another international org) would have an incentive to honor these agreements because their credibility when it comes to future such agreements relies on their past behavior.</p>
<p>To be slightly more concrete: The UN creates a new program, Retirement Early Autocrat Program (it got mangled in the translation from French). Every year, REAP diplomats go around to autocracies and convene autocrats and a sortition of citizens. At the conventions, they attempt to negotiate a deal—the autocrat peacefully retires in exchange for an income of $X in perpetuity. If the deal doesn’t go through, the REAPers leave and try again next year. If the deal is struck, REAPers take care of logistics (the autocrat should probably go into comfortable exile) and ensure the agreed upon payment is collected and delivered. If either party tries to renege on the agreement, the REAPers say, “No!”, and bring some enforcement mechanism to bear. They know that if they don’t, their whole program loses credibility and purpose.</p>
<h4 id="political-feasibility">Political feasibility</h4>
<p>Their are obvious political problems here. If a country refuses to honor their agreement, REAP is put in the position of sanctioning, occupying or otherwise penalizing a country with the intent of restoring a dictator to riches. This is politically unpalatable to say the least and so credible enforcement of this side of the bargain is difficult.</p>
<p>Workarounds include requiring prepayment (i.e. the country purchases an annuity for their dictator, presumably backed by REAP) and third parties subsidizing or entirely financing the agreement. It seems plausible that such agreements would often be less than the cost of military intervention which third parties are sometimes willing to undertake.</p>
<p>For example, direct war appropriations (a dramatic underestimate of the full cost) for the <a href="https://en.wikipedia.org/wiki/Iraq_War#Financial_cost">Iraq War</a> total $819 billion to date <span class="citation" data-cites="crawford2017">(Crawford <a href="#ref-crawford2017">2017</a>)</span>. If <a href="https://en.wikipedia.org/wiki/Saddam_Hussein">Sadam Hussein</a> had been expected to live to the ripe age of 96, this $819 billion would have purchased <span class="noted">an annuity paying around $56 billion a year</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. In 2003, the total GDP of Iraq was around $30 billion <span class="citation" data-cites="cia2004">(CIA <a href="#ref-cia2004">2004</a>)</span>.</p>


    </article></li>
    
</ul></main>

<nav class="pagination top">
  <ul>
  
    <li><a title="Oldest" href="./page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="./page/8/">⇠</a></li>
  
  
    <li class="inactive">⇢</li>
  
  
    <li class="inactive">⇥</li>
  
</ul>

</nav>
<nav class="pagination bottom">
  <ul>
  
    <li><a title="Oldest" href="./page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="./page/8/">⇠</a></li>
  
  
    <li class="inactive">⇢</li>
  
  
    <li class="inactive">⇥</li>
  
</ul>

</nav>


<header>
  <h1>Collectively Exhaustive</h1><span>A weblog</span>
  <hr />
</header>

<div class="main-menu top">
  <nav><ul>
    
      <li class="inactive"><strong>Home</strong></li>
    
    
      <li><a href="./posts/">By date</a></li>
    
    
      <li><a href="./tags/">By tag</a></li>
    
    
      <li><a href="./series/">By series</a></li>
    
    
      <li><a href="./tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="./atom.xml">RSS</a></li>
</ul></nav>

  <hr />
</div>

<div class="main-menu bottom">
  <hr />
  <nav><ul>
    
      <li class="inactive"><strong>Home</strong></li>
    
    
      <li><a href="./posts/">By date</a></li>
    
    
      <li><a href="./tags/">By tag</a></li>
    
    
      <li><a href="./series/">By series</a></li>
    
    
      <li><a href="./tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="./atom.xml">RSS</a></li>
</ul></nav>

</div>



<script defer type="text/javascript" src="./js/custom-elements.js"></script>

<script defer type="text/javascript" src="./js/vendors~custom-elements~ideal-calibration~is-development-easy~quorum~util-egal.js"></script>

<script defer type="text/javascript" src="./js/vendors~custom-elements~util-egal.js"></script>

</div>

  </body>
</html>
