<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.9">
    <title>Home—ColEx</title>
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,300,700,400italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="./css/default.css" />
    <link rel="icon" href="./images/favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="./images/favicon.ico" type="image/x-icon" />
    <script>
     if (!location.host.startsWith('localhost')) {
       var _rollbarConfig = {
         checkIgnore: function(isUncaught, args, payload) {
           return location.host.startsWith('localhost')
         },
         accessToken: "137e3ab64049469ba4a7d5e13a6f5aeb",
         captureUncaught: true,
         payload: {
           environment: "production"
         }
       };
       !function(r){function o(n){if(e[n])return e[n].exports;var t=e[n]={exports:{},id:n,loaded:!1};return r[n].call(t.exports,t,t.exports,o),t.loaded=!0,t.exports}var e={};return o.m=r,o.c=e,o.p="",o(0)}([function(r,o,e){"use strict";var n=e(1),t=e(4);_rollbarConfig=_rollbarConfig||{},_rollbarConfig.rollbarJsUrl=_rollbarConfig.rollbarJsUrl||"https://cdnjs.cloudflare.com/ajax/libs/rollbar.js/2.3.1/rollbar.min.js",_rollbarConfig.async=void 0===_rollbarConfig.async||_rollbarConfig.async;var a=n.setupShim(window,_rollbarConfig),l=t(_rollbarConfig);window.rollbar=n.Rollbar,a.loadFull(window,document,!_rollbarConfig.async,_rollbarConfig,l)},function(r,o,e){"use strict";function n(r){return function(){try{return r.apply(this,arguments)}catch(r){try{console.error("[Rollbar]: Internal error",r)}catch(r){}}}}function t(r,o){this.options=r,this._rollbarOldOnError=null;var e=s++;this.shimId=function(){return e},window&&window._rollbarShims&&(window._rollbarShims[e]={handler:o,messages:[]})}function a(r,o){var e=o.globalAlias||"Rollbar";if("object"==typeof r[e])return r[e];r._rollbarShims={},r._rollbarWrappedError=null;var t=new p(o);return n(function(){o.captureUncaught&&(t._rollbarOldOnError=r.onerror,i.captureUncaughtExceptions(r,t,!0),i.wrapGlobals(r,t,!0)),o.captureUnhandledRejections&&i.captureUnhandledRejections(r,t,!0);var n=o.autoInstrument;return(void 0===n||n===!0||"object"==typeof n&&n.network)&&r.addEventListener&&(r.addEventListener("load",t.captureLoad.bind(t)),r.addEventListener("DOMContentLoaded",t.captureDomContentLoaded.bind(t))),r[e]=t,t})()}function l(r){return n(function(){var o=this,e=Array.prototype.slice.call(arguments,0),n={shim:o,method:r,args:e,ts:new Date};window._rollbarShims[this.shimId()].messages.push(n)})}var i=e(2),s=0,d=e(3),c=function(r,o){return new t(r,o)},p=d.bind(null,c);t.prototype.loadFull=function(r,o,e,t,a){var l=function(){var o;if(void 0===r._rollbarDidLoad){o=new Error("rollbar.js did not load");for(var e,n,t,l,i=0;e=r._rollbarShims[i++];)for(e=e.messages||[];n=e.shift();)for(t=n.args||[],i=0;i<t.length;++i)if(l=t[i],"function"==typeof l){l(o);break}}"function"==typeof a&&a(o)},i=!1,s=o.createElement("script"),d=o.getElementsByTagName("script")[0],c=d.parentNode;s.crossOrigin="",s.src=t.rollbarJsUrl,e||(s.async=!0),s.onload=s.onreadystatechange=n(function(){if(!(i||this.readyState&&"loaded"!==this.readyState&&"complete"!==this.readyState)){s.onload=s.onreadystatechange=null;try{c.removeChild(s)}catch(r){}i=!0,l()}}),c.insertBefore(s,d)},t.prototype.wrap=function(r,o,e){try{var n;if(n="function"==typeof o?o:function(){return o||{}},"function"!=typeof r)return r;if(r._isWrap)return r;if(!r._rollbar_wrapped&&(r._rollbar_wrapped=function(){e&&"function"==typeof e&&e.apply(this,arguments);try{return r.apply(this,arguments)}catch(e){var o=e;throw"string"==typeof o&&(o=new String(o)),o._rollbarContext=n()||{},o._rollbarContext._wrappedSource=r.toString(),window._rollbarWrappedError=o,o}},r._rollbar_wrapped._isWrap=!0,r.hasOwnProperty))for(var t in r)r.hasOwnProperty(t)&&(r._rollbar_wrapped[t]=r[t]);return r._rollbar_wrapped}catch(o){return r}};for(var u="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,captureDomContentLoaded,captureLoad".split(","),f=0;f<u.length;++f)t.prototype[u[f]]=l(u[f]);r.exports={setupShim:a,Rollbar:p}},function(r,o){"use strict";function e(r,o,e){if(r){var t;"function"==typeof o._rollbarOldOnError?t=o._rollbarOldOnError:r.onerror&&!r.onerror.belongsToShim&&(t=r.onerror,o._rollbarOldOnError=t);var a=function(){var e=Array.prototype.slice.call(arguments,0);n(r,o,t,e)};a.belongsToShim=e,r.onerror=a}}function n(r,o,e,n){r._rollbarWrappedError&&(n[4]||(n[4]=r._rollbarWrappedError),n[5]||(n[5]=r._rollbarWrappedError._rollbarContext),r._rollbarWrappedError=null),o.handleUncaughtException.apply(o,n),e&&e.apply(r,n)}function t(r,o,e){if(r){"function"==typeof r._rollbarURH&&r._rollbarURH.belongsToShim&&r.removeEventListener("unhandledrejection",r._rollbarURH);var n=function(r){var e=r.reason,n=r.promise,t=r.detail;!e&&t&&(e=t.reason,n=t.promise),o&&o.handleUnhandledRejection&&o.handleUnhandledRejection(e,n)};n.belongsToShim=e,r._rollbarURH=n,r.addEventListener("unhandledrejection",n)}}function a(r,o,e){if(r){var n,t,a="EventTarget,Window,Node,ApplicationCache,AudioTrackList,ChannelMergerNode,CryptoOperation,EventSource,FileReader,HTMLUnknownElement,IDBDatabase,IDBRequest,IDBTransaction,KeyOperation,MediaController,MessagePort,ModalWindow,Notification,SVGElementInstance,Screen,TextTrack,TextTrackCue,TextTrackList,WebSocket,WebSocketWorker,Worker,XMLHttpRequest,XMLHttpRequestEventTarget,XMLHttpRequestUpload".split(",");for(n=0;n<a.length;++n)t=a[n],r[t]&&r[t].prototype&&l(o,r[t].prototype,e)}}function l(r,o,e){if(o.hasOwnProperty&&o.hasOwnProperty("addEventListener")){for(var n=o.addEventListener;n._rollbarOldAdd&&n.belongsToShim;)n=n._rollbarOldAdd;var t=function(o,e,t){n.call(this,o,r.wrap(e),t)};t._rollbarOldAdd=n,t.belongsToShim=e,o.addEventListener=t;for(var a=o.removeEventListener;a._rollbarOldRemove&&a.belongsToShim;)a=a._rollbarOldRemove;var l=function(r,o,e){a.call(this,r,o&&o._rollbar_wrapped||o,e)};l._rollbarOldRemove=a,l.belongsToShim=e,o.removeEventListener=l}}r.exports={captureUncaughtExceptions:e,captureUnhandledRejections:t,wrapGlobals:a}},function(r,o){"use strict";function e(r,o){this.impl=r(o,this),this.options=o,n(e.prototype)}function n(r){for(var o=function(r){return function(){var o=Array.prototype.slice.call(arguments,0);if(this.impl[r])return this.impl[r].apply(this.impl,o)}},e="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,_createItem,wrap,loadFull,shimId,captureDomContentLoaded,captureLoad".split(","),n=0;n<e.length;n++)r[e[n]]=o(e[n])}e.prototype._swapAndProcessMessages=function(r,o){this.impl=r(this.options);for(var e,n,t;e=o.shift();)n=e.method,t=e.args,this[n]&&"function"==typeof this[n]&&("captureDomContentLoaded"===n||"captureLoad"===n?this[n].apply(this,[t[0],e.ts]):this[n].apply(this,t));return this},r.exports=e},function(r,o){"use strict";r.exports=function(r){return function(o){if(!o&&!window._rollbarInitialized){r=r||{};for(var e,n,t=r.globalAlias||"Rollbar",a=window.rollbar,l=function(r){return new a(r)},i=0;e=window._rollbarShims[i++];)n||(n=e.handler),e.handler._swapAndProcessMessages(l,e.messages);window[t]=n,window._rollbarInitialized=!0}}}}]);
     }
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-113913768-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-113913768-1');
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          displayAlign: "left",
          displayIndent: "2em"
        });
    </script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG"></script>

    <script type="text/javascript">
if (/Trident/.test(navigator.userAgent)) {
  alert('I have reports that certain features are broken on Internet Explorer ' +
        '(e.g. SVG paths with markers, flexbox with the \'order\' attribute). ' +
        'This is a "Won\'t fix" at the moment so, if you\'re using IE, ' +
        'browse at your own risk.');
}
</script>
</head>
<body>
<div id="underlay">
<main><ul class="teasers">
  
    <li><article class="teaser">
        <h2><a href="./posts/assorted-links-xv/">Assorted links XV</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/links/">links</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="November 18, 2019">November 18, 2019</time>.</span>
       </div>

       

        <ol type="1">
<li><a href="https://www.gwern.net/docs/philo/2001-collins.pdf">Tacit Knowledge, Trust and the Q of Sapphire</a></li>
</ol>
<p>Much more interesting IMO than these short excerpts will suggest:</p>
<blockquote>
<p>For about 20 years, the team led by Vladimir Braginsky at Moscow State University, as part of a larger programmeon low dissipation systems, has been claiming to have measured quality factors (Qs) in sapphire up to 4x10^8 at room temperature. The ‘quality factor’ of a material indicates the rate of decay of its resonances — how long it will ‘ring’ if struck. […] But until the summerof 1999, no one outside Moscow State had succeeded in measuring a Q in sapphire higher than about 5x10’.</p>
</blockquote>
<blockquote>
<p>In the summer of 1998, after a series of failed efforts to measure Qs comparable to the Russian claims, members of a Glasgow University group visited Moscow State University for a week to learn the Russian technique. […] In neither case was a high-Q measurement achieved. Nevertheless, after only a few days in Russia, the Glasgow team had become convinced that the Russian results were correct.</p>
</blockquote>
<ol start="2" type="1">
<li><a href="https://www.knowablemagazine.org/article/health-disease/2019/human-challenge-trials">First, do harm</a></li>
</ol>
<blockquote>
<p>Studies that deliberately infect people with diseases are on the rise. They promise speedier vaccine development, but there’s a need to shore up informed consent.</p>
</blockquote>
<ol start="3" type="1">
<li><a href="https://www.academia.edu/19622919/Moral_Bias_and_Corrective_Practices">Moral Bias and Corrective Practices: A Pragmatist Perspective</a></li>
</ol>
<blockquote>
<p>Thus, the moral biases of slavery advocates proved largely immune to correction by the dominant methods of moral philosophy, which were deployed by white abolitionists. Ascent to the a priori led to abstract moral principles—the Golden Rule, the equality of humans before God—that settled nothing because their application to this world was contested. Table-turning exercises were ineffective for similar reasons. Reflective equilibrium did not clearly favor the abolitionists, given authoritarian, Biblical, and racist premises shared by white abolitionists and slavery advocates. No wonder only a handful of Southern whites turned against slavery on the basis of pure moral argument.</p>
</blockquote>
<ol start="4" type="1">
<li><a href="http://documents.worldbank.org/curated/en/514331468149391238/pdf/772610JRN0WBER0Box0377301B00PUBLIC0.pdf">A Panel Data Analysis of the Fungibility of Foreign Aid</a></li>
</ol>
<blockquote>
<p>The donor community has been increasingly concerned that development assistance intended for crucial social and economic sectors might be used directly or indirectly to fund unproductive military and other expenditures. The link between foreign aid and public spending is not straightforward because some aid may be “fungible.” This article empirically examines the impact of foreign aid on the recipient’s public expenditures, using cross-country samples of annual observations for 1971-90</p>
</blockquote>
<ol start="5" type="1">
<li><a href="http://crookedtimber.org/2012/05/30/in-soviet-union-optimization-problem-solves-you/">In Soviet Union, Optimization Problem Solves <em>You</em></a></li>
</ol>
<blockquote>
<p>The most plausible candidate [to making linear programming solutions feasible for economic planning problems] is to look for problems which are “separable”, where the constraints create very few connections among the variables. If we could divide the variables into two sets which had nothing at all to do with each other, then we could solve each sub-problem separately, at tremendous savings in time. The supra-linear, <span class="math inline">\(n^{3.5}\)</span> scaling would apply only within each sub-problem. We could get the optimal prices (or optimal plans) just by concatenating the solutions to sub-problems, with no extra work on our part.</p>
</blockquote>
<blockquote>
<p>Unfortunately, as Lenin is supposed to have said, “everything is connected to everything else”. […] A national economy simply does not break up into so many separate, non-communicating spheres which could be optimized independently.</p>
</blockquote>
<blockquote>
<p>So long as we are thinking like computer programmers, however, we might try a desperately crude hack, and just ignore all kinds of interdependencies between variables. If we did that, if we pretended that the over-all high-dimensional economic planning problem could be split into many separate low-dimensional problems, then we could speed things up immensely, by exploiting parallelism or distributed processing. […]</p>
</blockquote>
<blockquote>
<p>At this point, each processor is something very much like a firm, with a scope dictated by information-processing power, and the mis-matches introduced by their ignoring each other in their own optimization is something very much like “the anarchy of the market”.</p>
</blockquote>


        <a href="./posts/assorted-links-xv/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/reliability-moral-judgments/">The reliability of moral judgments: A survey and systematic(ish) review</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/ethics/">ethics</a></li>
    
      <li><a href="./tag/statistics/">statistics</a></li>
    
      <li><a href="./tag/review/">review</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="October 31, 2019">October 31, 2019</time>.</span>
       </div>

       
         <div class="abstract"><p>We’d like our moral judgments to be reliable—<a href="#what-would-it-mean-for-moral-judgments-to-be-unreliable">to be sensitive only to factors that we endorse as morally relevant</a>. <a href="#direct-empirical-evidence">Experimental studies</a> on a variety of putatively irrelevant factors—like the ordering of dilemmas and incidental disgust at time of evaluation—give some (but not strong, due to <a href="#appendix-qualitative-discussion-of-methodology">methodological issues</a> and limited data) reason to believe that our moral judgments do in practice track these irrelevant factors. <a href="#indirect-evidence">Theories about the origins and operations</a> of our moral faculties give further reason to suspect that our moral judgments are not perfectly reliable. There are a variety of <a href="#responses">responses</a> which try to rehabilitate our moral judgments—by <a href="#internal-validity">denying the validity of the experimental studies</a>, by blocking the inference to the <a href="#expertise">people</a> and <a href="#ecological-validity">situations</a> of most concern, by <a href="#sufficient">accepting their limited reliability and shrugging</a>, by <a href="#moral-engineering">accepting their limited reliability and working to overcome it</a>—but it’s not yet clear whether any of them do or can succeed.</p></div>
       

        
<div class="toc"><h5>Contents</h5>
<ul>
<li><a href="#intro">Intro</a><ul>
<li><a href="#what-are-moral-judgments">What are moral judgments?</a></li>
<li><a href="#what-would-it-mean-for-moral-judgments-to-be-unreliable">What would it mean for moral judgments to be unreliable?</a></li>
<li><a href="#why-do-we-care-about-the-alleged-unreliability-of-moral-judgments">Why do we care about the alleged unreliability of moral judgments?</a></li>
</ul></li>
<li><a href="#direct-empirical-evidence">Direct (empirical) evidence</a><ul>
<li><a href="#procedure">Procedure</a></li>
<li><a href="#order">Order</a></li>
<li><a href="#wording">Wording</a></li>
<li><a href="#disgust-and-cleanliness">Disgust and cleanliness</a></li>
<li><a href="#gender">Gender</a></li>
<li><a href="#culture-and-socioeconomic-status">Culture and socioeconomic status</a></li>
<li><a href="#personality">Personality</a></li>
<li><a href="#actorobserver">Actor/observer</a></li>
<li><a href="#summary">Summary</a></li>
</ul></li>
<li><a href="#indirect-evidence">Indirect evidence</a><ul>
<li><a href="#heuristics-and-biases">Heuristics and biases</a></li>
<li><a href="#neural">Neural</a></li>
<li><a href="#dual-process">Dual process</a></li>
<li><a href="#genes">Genes</a><ul>
<li><a href="#universal-moral-grammar">Universal moral grammar</a></li>
</ul></li>
<li><a href="#culture">Culture</a></li>
<li><a href="#moral-disagreements">Moral disagreements</a></li>
<li><a href="#summary-1">Summary</a></li>
</ul></li>
<li><a href="#responses">Responses</a><ul>
<li><a href="#internal-validity">Internal validity</a></li>
<li><a href="#expertise">Expertise</a></li>
<li><a href="#ecological-validity">Ecological validity</a></li>
<li><a href="#sufficient">Sufficient</a></li>
<li><a href="#ecologically-rational">Ecologically rational</a></li>
<li><a href="#second-order-reliability">Second-order reliability</a></li>
<li><a href="#moral-engineering">Moral engineering</a></li>
<li><a href="#summary-2">Summary</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#appendix-qualitative-discussion-of-methodology">Appendix: Qualitative discussion of methodology</a><ul>
<li><a href="#order-1">Order</a></li>
<li><a href="#wording-1">Wording</a></li>
<li><a href="#disgust-and-cleanliness-1">Disgust and cleanliness</a></li>
<li><a href="#gender-1">Gender</a></li>
<li><a href="#culture-and-socioeconomic-status-1">Culture and socioeconomic status</a></li>
<li><a href="#personality-1">Personality</a></li>
<li><a href="#actorobserver-1">Actor/observer</a></li>
</ul></li>
</ul>
</div>
<!-- Otherwise the sidenotes overlap with tables and I can't be bothered to fix it right now. -->
<p><span class="disable-sidenotes" style="display: none;"></span></p>
<p>(This post is painfully long. Coping advice: Each subsection within <a href="#direct-empirical-evidence">Direct (empirical) evidence</a>, within <a href="#indirect-evidence">Indirect evidence</a>, and within <a href="#responses">Responses</a> is pretty independent—feel free to dip in and out as desired. I’ve also put a list-formatted summary at the end of each these sections boiling down each subsection to one or two sentences.)</p>
<h3 id="intro">Intro</h3>
<blockquote>
Dan is a student council representative at his school. This semester he is in charge of scheduling discussions about academic issues. He often picks topics that appeal to both professors and students in order to stimulate discussion.
</blockquote>
<p>Is Dan’s behavior morally acceptable? On first glance, you’d be inclined to say yes. And even on the second and third glance, obviously, yes. Dan is a stand-up guy. But what if you’d been experimentally manipulated to feel disgust while reading the vignette? If we’re to believe <span class="citation" data-cites="wheatley2005hypnotic">(Wheatley and Haidt <a href="#ref-wheatley2005hypnotic" role="doc-biblioref">2005</a>)</span>, there’s a one-third chance you’d judge Dan as morally suspect. ‘One subject justified his condemnation of Dan by writing “it just seems like he’s up to something.” Another wrote that Dan seemed like a “popularity seeking snob.”’</p>
<p>The possibility that moral judgments track irrelevant factors like incidental disgust at the moment of evaluation is (to me, at least) alarming. But now that you’ve been baited, we can move on the boring, obligatory formalities.</p>


        <a href="./posts/reliability-moral-judgments/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/uncertainty-sensitivity-analysis-givewell-rankings/">Uncertainty and sensitivity analysis of GiveWell's top charity rankings</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/statistics/">statistics</a></li>
    
      <li><a href="./tag/development/">development</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/GiveWell%2520cost-effectiveness%2520analysis%2520analysis/">Series: GiveWell cost-effectiveness analysis analysis</a></nav>
        
        <span class="date">Published on <time datetime="August 29, 2019">August 29, 2019</time>.</span>
       </div>

       
         <div class="abstract"><p>Arguably, we don’t care about the exact cost-effectiveness estimates of each of GiveWell’s top charities. Instead, we care about their relative values. By using distance metrics across these multidimensional outputs, we can perform uncertainty and sensitivity analysis to answer questions about:</p>
<ul>
<li>how uncertain we are about the overall relative values of the charities</li>
<li>which input parameters this overall relative valuation is most sensitive to</li>
</ul></div>
       

        
<div class="toc"><h5>Contents</h5>
<ul>
<li><a href="#metrics-on-rankings">Metrics on rankings</a><ul>
<li><a href="#spearmans-footrule">Spearman’s footrule</a></li>
<li><a href="#kendalls-tau">Kendall’s tau</a></li>
<li><a href="#angular-distance">Angular distance</a></li>
</ul></li>
<li><a href="#results">Results</a><ul>
<li><a href="#uncertainties">Uncertainties</a></li>
<li><a href="#visual-sensitivity-analysis">Visual sensitivity analysis</a></li>
<li><a href="#delta-moment-independent-sensitivity-analysis">Delta moment-independent sensitivity analysis</a><ul>
<li><a href="#needs-more-meta">Needs more meta</a></li>
</ul></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#appendix">Appendix</a></li>
</ul>
</div>
<p>In the <a href="./posts/uncertainty-analysis-of-givewell-cea/">last</a> <a href="./posts/sensitivity-analysis-of-givewell-cea/">two</a> posts, we performed uncertainty and sensitivity analyses on GiveWell’s charity cost-effectiveness estimates. Our outputs were, respectively:</p>
<ul>
<li>probability distributions describing our uncertainty about the value per dollar obtained for each charity and</li>
<li>estimates of how sensitive each charity’s cost-effectiveness is to each of its input parameters</li>
</ul>
<p>One problem with this is that we are <a href="https://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/">not supposed to take the cost-effectiveness estimates literally</a>. Arguably, the real purpose of GiveWell’s analysis is not to produce exact numbers but to assess the relative quality of each charity evaluated.</p>
<p>Another issue is that by treating each cost-effectiveness estimate as independent we underweight parameters which are shared across many models. For example, the moral weight that ought to be assigned to increasing consumption shows up in many models. If we consider all the charity-specific models together, this input seems to become more important.</p>
<h3 id="metrics-on-rankings">Metrics on rankings</h3>
<p>We can solve both of these problems by abstracting away from particular values in the cost-effectiveness analysis and looking at the overall rankings returned. That is we want to transform:</p>
<figure>
<figcaption>
GiveWell’s cost-effectiveness estimates for its top charities
</figcaption>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Charity</th>
<th style="text-align: right;">Value per $10,000 donated</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">GiveDirectly</td>
<td style="text-align: right;">38</td>
</tr>
<tr class="even">
<td style="text-align: left;">The END Fund</td>
<td style="text-align: right;">222</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Deworm the World</td>
<td style="text-align: right;">738</td>
</tr>
<tr class="even">
<td style="text-align: left;">Schistosomiasis Control Initiative</td>
<td style="text-align: right;">378</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Sightsavers</td>
<td style="text-align: right;">394</td>
</tr>
<tr class="even">
<td style="text-align: left;">Malaria Consortium</td>
<td style="text-align: right;">326</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Against Malaria Foundation</td>
<td style="text-align: right;">247</td>
</tr>
<tr class="even">
<td style="text-align: left;">Helen Keller International</td>
<td style="text-align: right;">223</td>
</tr>
</tbody>
</table>
</figure>
<p>into:</p>
<figure>
<figcaption>
Givewell’s top charities ranked from most cost-effective to least
</figcaption>
<ul>
<li>Deworm the World</li>
<li>Sightsavers</li>
<li>Schistosomiasis Control Initiative</li>
<li>Malaria Consortium</li>
<li>Against Malaria Foundation</li>
<li>Helen Keller International</li>
<li>The END Fund</li>
<li>GiveDirectly</li>
</ul>
</figure>
<p>But how do we usefully express <span class="noted">probabilities over rankings</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> (rather than probabilities over simple cost-effectivness numbers)? The approach we’ll follow below is to characterize a ranking produced by a run of the model by computing its distance from the reference ranking listed above (i.e. GiveWell’s current best estimate). Our output probability distribution will then express how far we expect to be from the reference ranking—how much we might learn about the ranking with more information on the inputs. For example, if the distribution is narrow and near 0, that means our uncertain input parameters mostly produce results similar to the reference ranking. If the distribution is wide and far from 0, that means our uncertain input parameters produce results that are highly uncertain and not necessarily similar to the reference ranking.</p>
<h4 id="spearmans-footrule">Spearman’s footrule</h4>
<p>What is this mysterious distance metric between rankings that enables the above approach? One such metric is called Spearman’s footrule distance. It’s defined as:</p>
<div class=".skippable">
<p><span class="math display">\[d_{fr}(u, v) = \sum_{c \in A} |\text{pos}(u,c) - \text{pos}(v, c)|\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are rankings,</li>
<li><span class="math inline">\(c\)</span> varies over all the elements <span class="math inline">\(A\)</span> of the rankings and</li>
<li><span class="math inline">\(\text{pos}(r, x)\)</span> returns the integer position of item <span class="math inline">\(x\)</span> in ranking <span class="math inline">\(r\)</span>.</li>
</ul>
</div>
<p>In other words, the footrule distance between two rankings is the sum over all items of the (absolute) difference in positions for each item. (We also add a normalization factor so that the distance varies ranges from 0 to 1 but omit that trivia here.)</p>
<p>So the distance between A, B, C and A, B, C is 0; the (unnormalized) distance between A, B, C and C, B, A is 4; and the (unnormalized) distance between A, B, C and B, A, C is 2.</p>
<h4 id="kendalls-tau">Kendall’s tau</h4>
<p>Another common distance metric between rankings is <a href="https://en.wikipedia.org/wiki/Kendall_tau_distance">Kendall’s tau</a>. It’s defined as:</p>
<div class=".skippable">
<p><span class="math display">\[d_{tau}(u, v) = \sum_{\{i,j\} \in P} \bar{K}_{i,j}(u, v)\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are again rankings,</li>
<li><span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are items in the set of unordered pairs <span class="math inline">\(P\)</span> of distinct elements in <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span></li>
<li><span class="math inline">\(\bar{K}_{i,j}(u, v) = 0\)</span> if <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are in the same order (concordant) in <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> and <span class="math inline">\(\bar{K}_{i,j}(u, v) = 1\)</span> otherwise (discordant)</li>
</ul>
</div>
<p>In other words, the Kendall tau distance looks at all possible pairs across items in the rankings and counts up the ones where the two rankings disagree on the ordering of these items. (There’s also a normalization factor that we’ve again omitted so that the distance ranges from 0 to 1.)</p>
<p>So the distance between A, B, C and A, B, C is 0; the (unnormalized) distance between A, B, C and C, B, A is 3; and the (unnormalized) distance between A, B, C and B, A, C is 1.</p>
<h4 id="angular-distance">Angular distance</h4>
<p>One drawback of the above metrics is that they throw away information in going from the table with cost-effectiveness estimates to a simple ranking. What would be ideal is to keep that information and find some other distance metric that still emphasizes the relationship between the various numbers rather than their precise values.</p>
<p>Angular distance is a metric which satisfies these criteria. We can regard the table of charities and cost-effectiveness values as an 8-dimensional vector. When our output produces another vector of cost-effectiveness estimates (one for each charity), we can compare this to our reference vector by finding <span class="noted">the angle between the two</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>


        <a href="./posts/uncertainty-sensitivity-analysis-givewell-rankings/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/sensitivity-analysis-of-givewell-cea/">Sensitivity analysis of GiveWell's cost-effectiveness analysis</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/statistics/">statistics</a></li>
    
      <li><a href="./tag/development/">development</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/GiveWell%2520cost-effectiveness%2520analysis%2520analysis/">Series: GiveWell cost-effectiveness analysis analysis</a></nav>
        
        <span class="date">Published on <time datetime="August 28, 2019">August 28, 2019</time>.</span>
       </div>

       
         <div class="abstract"><p>Visual (scatter plot) and delta moment-independent sensitivity analysis on GiveWell’s cost-effectiveness models show which input parameters the cost-effectiveness estimates are most sensitive to. Preliminary results (given our input uncertainty) show that some input parameters are much more influential on the final cost-effectiveness estimates for each charity than others.</p></div>
       

        
<div class="toc"><h5>Contents</h5>
<ul>
<li><a href="#sensitivity-analysis">Sensitivity analysis</a></li>
<li><a href="#visual-sensitivity-analysis">Visual sensitivity analysis</a><ul>
<li><a href="#direct-cash-transfers">Direct cash transfers</a><ul>
<li><a href="#givedirectly">GiveDirectly</a></li>
</ul></li>
<li><a href="#deworming">Deworming</a><ul>
<li><a href="#the-end-fund">The END Fund</a></li>
<li><a href="#deworm-the-world">Deworm the World</a></li>
<li><a href="#schistosomiasis-control-initiative">Schistosomiasis Control Initiative</a></li>
<li><a href="#sightsavers">Sightsavers</a></li>
</ul></li>
<li><a href="#seasonal-malaria-chemoprevention">Seasonal malaria chemoprevention</a><ul>
<li><a href="#malaria-consortium">Malaria Consortium</a></li>
</ul></li>
<li><a href="#vitamin-a-supplementation">Vitamin A supplementation</a><ul>
<li><a href="#helen-keller-international">Helen Keller International</a></li>
</ul></li>
<li><a href="#bednets">Bednets</a><ul>
<li><a href="#against-malaria-foundation">Against Malaria Foundation</a></li>
</ul></li>
</ul></li>
<li><a href="#delta-moment-independent-sensitivity-analysis">Delta moment-independent sensitivity analysis</a><ul>
<li><a href="#direct-cash-transfers-1">Direct cash transfers</a><ul>
<li><a href="#givedirectly-1">GiveDirectly</a></li>
</ul></li>
<li><a href="#deworming-1">Deworming</a><ul>
<li><a href="#the-end-fund-1">The END Fund</a></li>
<li><a href="#deworm-the-world-1">Deworm the World</a></li>
<li><a href="#schistosomiasis-control-initiative-1">Schistosomiasis Control Initiative</a></li>
<li><a href="#sightsavers-1">Sightsavers</a></li>
<li><a href="#deworming-comment">Deworming comment</a></li>
</ul></li>
<li><a href="#seasonal-malaria-chemoprevention-1">Seasonal malaria chemoprevention</a><ul>
<li><a href="#malaria-consortium-1">Malaria Consortium</a></li>
</ul></li>
<li><a href="#vitamin-a-supplementation-1">Vitamin A supplementation</a><ul>
<li><a href="#hellen-keller-international">Hellen Keller International</a></li>
</ul></li>
<li><a href="#bednets-1">Bednets</a><ul>
<li><a href="#against-malaria-foundation-1">Against Malaria Foundation</a></li>
</ul></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#appendix">Appendix</a></li>
</ul>
</div>
<p><a href="./posts/uncertainty-analysis-of-givewell-cea/">Last time</a> we introduced GiveWell’s cost-effectiveness analysis which uses a spreadsheet model to take point estimates of uncertain input parameters to point estimates of uncertain results. We adjusted this approach to take probability distributions on the input parameters and in exchange got probability distributions on the resulting cost-effectiveness estimates. But this machinery lets us do more. Now that we’ve completed an uncertainty analysis, we can move on to sensitivity analysis.</p>
<h3 id="sensitivity-analysis">Sensitivity analysis</h3>
<p>The basic idea of <a href="https://en.wikipedia.org/wiki/Sensitivity_analysis">sensitivity analysis</a> is, when working with uncertain values, to see which input values most affect the output when they vary. For example, if you have the equation <span class="math inline">\(f(a, b) = 2^a + b\)</span> and each of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> varies uniformly over the range from 5 to 10, <span class="math inline">\(f(a, b)\)</span> is much more sensitive to <span class="math inline">\(a\)</span> then <span class="math inline">\(b\)</span>. A sensitivity analysis is practically useful in that it can offer you guidance as to which parameters in your model it would be most useful to investigate further (i.e. to narrow their uncertainty).</p>
<h3 id="visual-sensitivity-analysis">Visual sensitivity analysis</h3>
<p>The first kind of sensitivity analysis we’ll run is just to look at scatter plots comparing each input parameter to the final cost-effectiveness estimates. We can imagine these scatter plots as the result of running <span class="noted">the following procedure many times</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>: sample a single value from the probability distribution for each input parameter and run the calculation on these values to determine a result value. If we repeat this procedure enough times, it starts to approximate the true values of the probability distributions.</p>
<p>(One nice feature of this sort of analysis is that we see how the output depends on a particular input even in the face of variations in all the other inputs—we don’t hold everything else constant. In other words, this is a <a href="https://en.wikipedia.org/wiki/Sensitivity_analysis#Local_methods">global</a> sensitivity analysis.)</p>
<p>(Caveat: We are again pretending that we are equally uncertain about each input parameter and the results reflect this limitation. To see the analysis result for different input uncertainties, edit and run <a href="https://colab.research.google.com/drive/1TCXBi7lF69Xaaygub5HGD6-Rb6qE924e#sandboxMode=true">the Jupyter notebook</a>.)</p>
<h4 id="direct-cash-transfers">Direct cash transfers</h4>
<h5 id="givedirectly">GiveDirectly</h5>
<figure class="natural-fig">
<img src="./images/givewell-analysis/regressions-big-GiveDirectly-value_per_dollar.png" title="fig:" alt="Scatter plots showing sensitivity of GiveDirectly’s cost-effectiveness to each input parameter" />
<figcaption>
Scatter plots showing sensitivity of GiveDirectly’s cost-effectiveness to each input parameter
</figcaption>
</figure>
<p>The scatter plots show that, given our choice of input uncertainty, the output is most sensitive (i.e. the scatter plot for these parameters shows the greatest directionality) to the input parameters:</p>
<figure class="big-fig">
<figcaption>
Highlighted input factors to which result is highly sensitive
</figcaption>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 25%" />
<col style="width: 41%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Input</th>
<th style="text-align: left;">Type of uncertainty</th>
<th style="text-align: left;">Meaning/importance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">value of increasing ln consumption per capita per annum</td>
<td style="text-align: left;">Moral</td>
<td style="text-align: left;">Determines final conversion between empirical outcomes and value</td>
</tr>
<tr class="even">
<td style="text-align: left;">transfer as percent of total cost</td>
<td style="text-align: left;">Operational</td>
<td style="text-align: left;">Determines cost of results</td>
</tr>
<tr class="odd">
<td style="text-align: left;">return on investment</td>
<td style="text-align: left;">Opportunities available to recipients</td>
<td style="text-align: left;">Determines stream of consumption over time</td>
</tr>
<tr class="even">
<td style="text-align: left;">baseline consumption per capita</td>
<td style="text-align: left;">Empirical</td>
<td style="text-align: left;">Diminishing marginal returns to consumption mean that baseline consumption matters</td>
</tr>
</tbody>
</table>
</figure>


        <a href="./posts/sensitivity-analysis-of-givewell-cea/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/uncertainty-analysis-of-givewell-cea/">Uncertainty analysis of GiveWell's cost-effectiveness analysis</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/statistics/">statistics</a></li>
    
      <li><a href="./tag/development/">development</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/GiveWell%2520cost-effectiveness%2520analysis%2520analysis/">Series: GiveWell cost-effectiveness analysis analysis</a></nav>
        
        <span class="date">Published on <time datetime="August 27, 2019">August 27, 2019</time>.</span>
       </div>

       
         <div class="abstract"><p>GiveWell produces cost-effectiveness models of its top charities. These models take as inputs many uncertain parameters. Instead of representing those uncertain parameters with point estimates—as the cost-effectiveness analysis spreadsheet does—we can (should) represent them with probability distributions. Feeding probability distributions into the models allows us to output explicit probability distributions on the cost-effectiveness of each charity.</p></div>
       

        
<div class="toc"><h5>Contents</h5>
<ul>
<li><a href="#givewells-cost-effectiveness-analysis">GiveWell’s cost-effectiveness analysis</a></li>
<li><a href="#uncertain-inputs">Uncertain inputs</a><ul>
<li><a href="#is-this-really-necessary">Is this really necessary?</a></li>
<li><a href="#computers-are-nice">Computers are nice</a></li>
</ul></li>
<li><a href="#analysis">Analysis</a><ul>
<li><a href="#model">Model</a></li>
<li><a href="#inputs">Inputs</a></li>
<li><a href="#results">Results</a></li>
</ul></li>
<li><a href="#conclusions">Conclusions</a></li>
</ul>
</div>
<h3 id="givewells-cost-effectiveness-analysis">GiveWell’s cost-effectiveness analysis</h3>
<p><a href="https://www.givewell.org/">GiveWell</a>, an in-depth charity evaluator, makes their detailed spreadsheets models <a href="https://docs.google.com/spreadsheets/d/1d255LKz11L3V-OgOEns9WvJzpnVeaLTcEP1HD4lC478/edit#gid=1537947274">available</a> for public review. These spreadsheets estimate the value per dollar of donations to their 8 top charities: GiveDirectly, Deworm the World, Schistosomiasis Control Initiative, Sightsavers, Against Malaria Foundation, Malaria Consortium, Helen Keller International, and the END Fund. For each charity, a model is constructed taking input values to an estimated value per dollar of donation to that charity. The inputs to these models vary from parameters like “malaria prevalence in areas where AMF operates” to “value assigned to averting the death of an individual under 5”.</p>
<p>Helpfully, GiveWell isolates the input parameters it deems as most uncertain. These can be found in the “User inputs” and “Moral weights” tabs of their spreadsheet. Outsiders interested in the top charities can reuse GiveWell’s model but supply their own perspective by adjusting the values of the parameters in these tabs.</p>
<p>For example, if I go to the “Moral weights” tab and run the calculation with a 0.1 value for doubling consumption for one person for one year—instead of the default value of 1—I see the effect of this modification on the final results: deworming charities look much less effective since their primary effect is on income.</p>
<h3 id="uncertain-inputs">Uncertain inputs</h3>
<p>GiveWell provides the ability to adjust these input parameters and observe altered output because the inputs are fundamentally uncertain. But our uncertainty means that picking any particular value as input for the calculation misrepresents our state of knowledge. From a <a href="https://en.wikipedia.org/wiki/Bayesian_probability">subjective Bayesian</a> point of view, the best way to represent our state of knowledge on the input parameters is with a <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> over the values the parameter could take. For example, I could say that a negative value for increasing consumption seems very improbable to me but that a wide range of positive values seem about equally plausible. Once we specify a probability distribution, we can feed these distributions into the model and, in principle, we’ll end up with a probability distribution over our results. This probability distribution on the results helps us understand the uncertainty contained in our estimates and <a href="https://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/">how literally</a> we should take them.</p>
<h4 id="is-this-really-necessary">Is this really necessary?</h4>
<p>Perhaps that sounds complicated. How are we supposed to multiply, add and otherwise manipulate arbitrary probability distributions in the way our models require? Can we somehow reduce our uncertain beliefs about the input parameters to point estimates and run the calculation on those? One candidate is to take the single most likely value of each input and using that value in our calculations. This is the approach the current cost-effectiveness analysis takes (assuming you provide input values selected in this way). Unfortunately, the output of running the model on these inputs is necessarily a point value and gives no information about the uncertainty of the results. Because the results are probably highly uncertain, losing this information and being unable to talk about the uncertainty of the results is a major loss. A second possibility is to take lower bounds on the input parameters and run the calculation on these values, and to take the upper bounds on the input parameters and run the calculation on these values. This will produce two bounding values on our results, but it’s hard to give them a useful meaning. If the lower and upper bounds on our inputs describe, for example, a 95% confidence interval, the lower and upper bounds on the result don’t (usually) describe a 95% confidence interval.</p>
<h4 id="computers-are-nice">Computers are nice</h4>
<p>If we had to proceed analytically, working with probability distributions throughout, the model would indeed be troublesome and we might have to settle for one of the above approaches. But we live in the future. We can use computers and <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo methods</a> to numerically approximate the results of working with probability distributions while leaving our models clean and unconcerned with these probabilistic details. <a href="https://www.getguesstimate.com/">Guesstimate</a> is a tool that works along these lines and bills itself as “A spreadsheet for things that aren’t certain”.</p>
<h3 id="analysis">Analysis</h3>
<p>We have the beginnings of a plan then. We can implement GiveWell’s cost-effectiveness models in a Monte Carlo framework (<a href="https://docs.pymc.io/">PyMC3</a> in this case), specify probability distributions over the input parameters, and finally run the calculation and look at the uncertainty that’s been propagated to the results.</p>


        <a href="./posts/uncertainty-analysis-of-givewell-cea/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/conditioning-causal-graphs/">Conditioning in causal graphs</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/causality/">causality</a></li>
    
      <li><a href="./tag/interactive/">interactive</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/Graphical%2520causal%2520models/">Series: Graphical causal models</a></nav>
        
        <span class="date">Published on <time datetime="July 18, 2019">July 18, 2019</time>.</span>
       </div>

       

        
<div class="toc"><h5>Contents</h5>
<ul>
<li><a href="#causal-triplets-again">Causal triplets, again</a><ul>
<li><a href="#chains">Chains</a></li>
<li><a href="#forks">Forks</a></li>
<li><a href="#inverted-forks">Inverted forks</a></li>
</ul></li>
<li><a href="#d-separation-and-d-connection-along-a-path">d-separation and d-connection along a path</a></li>
<li><a href="#d-separation-and-d-connection-on-graphs">d-separation and d-connection on graphs</a><ul>
<li><a href="#conditioning-on-descendants-of-colliders">Conditioning on descendants of colliders</a></li>
</ul></li>
<li><a href="#interactive">Interactive</a></li>
<li><a href="#postscript">Postscript</a></li>
</ul>
</div>
<p>As mentioned in the warnings on the <a href="./posts/babys-first-graphical-causal-models/">first post on graphical causal models</a>, I’ve been lying to you so far. But it was for a good reason: that sweet, sweet expository simplicity. So far, all our definitions, algorithms, etc. have proceeded without any acknowledgment of the social scientists’ favorite statistical tool: <span class="noted"><a href="https://en.wikipedia.org/wiki/Controlling_for_a_variable">controlling for a variable</a></span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>In this post, we’ll introduce the concept of conditioning to our graphical causal models framework and see how it both complicates things and offers new possibilities. (This post deliberately mirrors the structure of <a href="./posts/babys-first-graphical-causal-models/">that one</a> so it may be handy to have it open in a second tab/window for comparison purposes.)</p>
<h3 id="causal-triplets-again">Causal triplets, again</h3>
<p>We started out by talking about three types of causal triplets: chains, forks and inverted forks. For convenience, here is the summary table we ended up with:</p>
<figure class="triplets-table">
<figcaption>
Types of causal triplets
</figcaption>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Name of triplet</th>
<th style="text-align: left;">Name of central vertex</th>
<th style="text-align: left;">Diagram</th>
<th style="text-align: left;">Ends (A and C) dependent?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Chain</td>
<td style="text-align: left;">Mediator/Traverse</td>
<td style="text-align: left;">A → B → C</td>
<td style="text-align: left;">Causally (probably)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Fork</td>
<td style="text-align: left;">Confounder/Common cause</td>
<td style="text-align: left;">A ← B → C</td>
<td style="text-align: left;">Noncausally</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Inverted fork</td>
<td style="text-align: left;">Collider/Common effect</td>
<td style="text-align: left;">A → B ← C</td>
<td style="text-align: left;">No</td>
</tr>
</tbody>
</table>
</figure>
<p>When we add the possibility of conditioning, things change dramatically:</p>
<figure class="triplets-table">
<figcaption>
Types of causal triplets with conditioning on central vertex
</figcaption>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Name of triplet</th>
<th style="text-align: left;">Name of central vertex</th>
<th style="text-align: left;">Diagram</th>
<th style="text-align: left;">Ends (A and C) dependent?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Chain</td>
<td style="text-align: left;">Mediator/Traverse</td>
<td style="text-align: left;">A → B → C</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">Fork</td>
<td style="text-align: left;">Confounder/Common cause</td>
<td style="text-align: left;">A ← B → C</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Inverted fork</td>
<td style="text-align: left;">Collider/common effect</td>
<td style="text-align: left;">A → B ← C</td>
<td style="text-align: left;">Noncausally</td>
</tr>
</tbody>
</table>
</figure>
<p>The complete reversal of in/dependence occasioned by conditioning on the middle vertex may be a bit surprising. There’s a certain reflex that says when ever you want to draw a clean causal story out of messy data, conditioning on more stuff will help you. But as we see here, <span class="noted">that’s not generally true</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Conditioning can also introduce spurious correlation.</p>


        <a href="./posts/conditioning-causal-graphs/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/instrumental-variables-on-causal-graphs/">Instrumental variables on causal graphs</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/causality/">causality</a></li>
    
      <li><a href="./tag/interactive/">interactive</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/Graphical%2520causal%2520models/">Series: Graphical causal models</a></nav>
        
        <span class="date">Published on <time datetime="June 20, 2019">June 20, 2019</time>.</span>
       </div>

       

        
<div class="toc"><h5>Contents</h5>
<ul>
<li><a href="#instrumental-variables">Instrumental variables</a></li>
<li><a href="#instrumental-variables-on-causal-graphs">Instrumental variables on causal graphs</a><ul>
<li><a href="#a-brief-notational-interlude">A brief notational interlude</a></li>
<li><a href="#defined">Defined</a></li>
<li><a href="#interactive">Interactive</a></li>
<li><a href="#explained">Explained</a><ul>
<li><a href="#compatible-models">Compatible models</a></li>
<li><a href="#the-instrumental-variable">The instrumental variable</a></li>
<li><a href="#d-separations">d-separations</a></li>
<li><a href="#model-selection">Model selection</a></li>
</ul></li>
<li><a href="#as-model-selection">As model selection</a></li>
</ul></li>
</ul>
</div>
<p><a href="./posts/flip-it-reverse-it-graphical-causal-models/">Last time</a> we talked about viewing d-separation as a tool for model selection. But we’re pretty limited in the causal models we can distinguish between by only observing our variables of interest—any two graphs with the same set of d-separations are indistinguishable. <a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation">Instrumental variables</a> are a common tool for trying to get around the limitations of purely observational data.</p>
<h3 id="instrumental-variables">Instrumental variables</h3>
<p>Instrumental variables (IV) are variables that we’re not intrinsically interested in but that we look at in an attempt to suss out causality. The instrument must be correlated with our cause, but its only impact on the effect should be via the cause.</p>
<p>The classic example is about—you guessed it—smoking. Because running an RCT on smoking is ethically verboten, we’re limited to observational data. How can we determine if smoking causes lung cancer from observational data alone? An instrumental variable! To reiterate, we want a factor that affects smoking prevalence but (almost certainly) does not affect lung cancer in other ways. Finding an instrument that satisfies the <abbr title="instrumental variable">IV</abbr> criteria generally seems to require substantial creativity. Can you think of an instrument for the causal effect of smoking on lung cancer?</p>
<p>…</p>
<p>An instrument that meets these criteria is a tax on cigarettes. We expect smoking to decrease as taxes increase, but it seems hard to imagine a cigarette tax otherwise having an effect on lung cancer.</p>
<h3 id="instrumental-variables-on-causal-graphs">Instrumental variables on causal graphs</h3>
<p>Okay, so that’s what <abbr title="instrument variable">IV</abbr>s are at a high level. But what are they concretely in the graphical causal model setting we’ve been developing?</p>
<h4 id="a-brief-notational-interlude">A brief notational interlude</h4>
<p>We’ll get this out of the way here:</p>
<ul>
<li><span class="math inline">\(\perp\!\!\!\perp\)</span> is the symbol for d-separation</li>
<li>Once we add the strikethrough, <span class="math inline">\(\not\!\!{\perp\!\!\!\perp}\)</span> mean d-connected.</li>
<li>If <span class="math inline">\(G\)</span> is a graph, <span class="math inline">\(G_{\overline{X}}\)</span>, is <span class="math inline">\(G\)</span> in which <span class="noted">all the edges pointing to vertex X have been removed</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</li>
</ul>
<h4 id="defined">Defined</h4>
<p>We’ll start with the definition and then try to build up a feel for it. An instrumental variable X for the causal effect of Y on Z in graph G must be:</p>
<ol type="1">
<li>d-connected to our cause Y—<span class="math inline">\((X \not\!\!{\perp\!\!\!\perp} Y)_G\)</span></li>
<li>d-separated from our effect Z after severing the cause Y from all its parents—<span class="math inline">\((X \perp\!\!\!\perp Z)_{G_\overline{Y}}\)</span></li>
</ol>


        <a href="./posts/instrumental-variables-on-causal-graphs/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/flip-it-reverse-it-graphical-causal-models/">Flip it and reverse it</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/causality/">causality</a></li>
    
      <li><a href="./tag/interactive/">interactive</a></li>
    
</ul></nav>

        
          <nav><a class="series" href="./series/Graphical%2520causal%2520models/">Series: Graphical causal models</a></nav>
        
        <span class="date">Published on <time datetime="June 17, 2019">June 17, 2019</time>.</span>
       </div>

       
         <div class="abstract"><p>Last time we found the d-separations that correspond to a graph. This time, we find the graphs that correspond to a set of d-separations. Which is more useful because we generally know d-separations and generally don’t know graphs.</p></div>
       

        <p><a href="./posts/babys-first-graphical-causal-models/">Last time</a> we talked about causal graphs, what d-separation and d-connection mean, and how to infer these properties from a causal graph. But this isn’t terribly useful because it requires that we have a fully specified causal graph. If we’re performing research in new or uncertain areas, we have data rather than a causal graph. And this data tells us about d-separations (variables that are independent of each other) and d-connections (variables that are correlated). So our work last time was exactly backwards: graphs to d-separations. This time we’ll go from d-separations to graphs.</p>
<h3 id="model-selection">Model selection</h3>
<p>One way to think about d-separation and d-connection is as helping us with model selection. Last time we presented</p>
<figure>
<img src="./images/smoking-graph.svg" id="smoking-graph" alt /><figcaption>Smoking is causally associated with both lung cancer and yellow fingers</figcaption>
</figure>
<p>as one possible causal model regarding smoking. But it’s not the only possibility. We might also be worried that the true causal structure looks like this (just go with it):</p>
<figure>
<img src="./images/smoking-graph-silly.svg" id="smoking-graph-silly" alt /><figcaption>Yellow fingers are independently caused by smoking and lung cancer</figcaption>
</figure>
<p>How can we tell them apart? Can we use observational data alone? In this case, observational data alone is enough to distinguish between these two causal models! The key is that the two models have different sets of d-separations. In the original model, all the vertices are d-connected and there are no d-separations (this must be the case since there are no colliders). In the second (silly) model, “smoking” and “lung cancer” are d-separated because “yellow fingers” is a collider between them. If our data show that smoking and lung cancer are independent, we must rule out the first model and prefer the second. If the two variables are correlated, we must rule out the second model and prefer the first.</p>
<p>This is a procedure that works generally:</p>
<ol type="1">
<li>Draw out the plausible graphical causal models that include all the variables you have data on</li>
<li>Determine the d-separations for each plausible model</li>
<li>Determine the variables in your data that are independent</li>
<li>Retain the models from step 1 whose d-separations in step 2 are compatible with the data analysis in step 3</li>
</ol>
<p>The ideal is that there’s only one model left at the end of step 4. However, it’s possible to end up with none. This means that step 1 wasn’t permissive enough and more models need to be considered. It’s also possible to end up with more than one model. Not all models are distinguishable by observational data alone. This occurs whenever two models have the same set of d-separations.</p>


        <a href="./posts/flip-it-reverse-it-graphical-causal-models/" class="full-post">Full post</a>

    </article></li>
    <hr />
  
    <li><article class="teaser">
        <h2><a href="./posts/assorted-links-xiv/">Assorted links XIV</a></h2>
       <div class="metadata">
        <nav class="tags"><ul>
    
      <li><a href="./tag/links/">links</a></li>
    
</ul></nav>

        
        <span class="date">Published on <time datetime="June 14, 2019">June 14, 2019</time>.</span>
       </div>

       

        <ol type="1">
<li><a href="https://www.nature.com/articles/s41467-019-10306-w">Augmented manipulation ability in humans with six-fingered hands</a></li>
</ol>
<blockquote>
<p>can the human brain deal with the complexity to control an extra limb and yield advantages from it? […] Anatomical MRI of the supernumerary finger (SF) revealed that it is actuated by extra muscles and nerves, and fMRI identified a distinct cortical representation of the SF. […] Polydactyly subjects were able to coordinate the SF with their other fingers for more complex movements than five fingered subjects, and so carry out with only one hand tasks normally requiring two hands.</p>
</blockquote>
<ol start="2" type="1">
<li><a href="http://spiritleveldelusion.blogspot.com/2019/03/the-spirit-level-ten-years-on.html">The Spirit Level ten years on</a></li>
</ol>
<blockquote>
<p>In summary, most of the biggest claims made by Wilkinson and Pickett in The Spirit Level look even weaker today than they did when the book was published. Only one of the six associations stand up under W &amp; P’s own methodology and none of them stand up when the full range of countries is analysed. In the case of life expectancy - the very flagship of The Spirit Level - the statistical association is the opposite of what the hypothesis predicts.</p>
</blockquote>
<blockquote>
<p>If The Spirit Level hypothesis were correct, it would produce robust and consistent results over time as the underlying data changes. Instead, it seems to be extremely fragile, only working when a very specific set of statistics are applied to a carefully selected list of countries.</p>
</blockquote>
<ol start="3" type="1">
<li><a href="https://twitter.com/backus/status/1110331165007704069">I’ve been called out</a></li>
</ol>
<blockquote>
<p>The allure of “meta” and “axiomatic first principles” is that it’s kinda like get-rich-quick thinking but for epistemics. Get a few abstractions really right and potentially earn more than you would grinding as an object-level wage slave for decades.</p>
</blockquote>
<ol start="4" type="1">
<li><a href="https://phenomenalworld.org/metaresearch/experiments-for-policy-choice">Experiments for Policy Choice</a></li>
</ol>
<blockquote>
<p>Trying to identify the best policy is different from estimating the precise impact of every individual policy: as long as we can identify the best policy, we do not care about the precise impacts of inferior policies. Yet, despite this, most experiments follow protocols that are designed to figure out the impact of every policy, even the obviously inferior ones.</p>
</blockquote>
<ol start="5" type="1">
<li><a href="https://www.sciencemag.org/news/2016/12/six-cloned-horses-help-rider-win-prestigious-polo-match">Six cloned horses help rider win prestigious polo match</a></li>
</ol>
<blockquote>
<p>Cambiaso rode six different horses to help his team win. […] What is noteworthy is that all six horses were clones of the same mare—they’re named Cuartetera 01 through 06. […] “Every scientist that deals with epigenetics told me this would never work,” says Meeker</p>
</blockquote>


        <a href="./posts/assorted-links-xiv/" class="full-post">Full post</a>

    </article></li>
    
</ul></main>

<nav class="pagination top">
  <ul>
  
    <li><a title="Oldest" href="./page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="./page/16/">⇠</a></li>
  
  
    <li class="inactive">⇢</li>
  
  
    <li class="inactive">⇥</li>
  
</ul>

</nav>
<nav class="pagination bottom">
  <ul>
  
    <li><a title="Oldest" href="./page/1/">⇤</a></li>
  
  
    <li><a title="Older" href="./page/16/">⇠</a></li>
  
  
    <li class="inactive">⇢</li>
  
  
    <li class="inactive">⇥</li>
  
</ul>

</nav>


<header>
  <h1>Collectively Exhaustive</h1><span>A weblog</span>
  <hr />
</header>

<div class="main-menu top">
  <nav><ul>
    
      <li class="inactive"><strong>Home</strong></li>
    
    
      <li><a href="./posts/">By date</a></li>
    
    
      <li><a href="./tags/">By tag</a></li>
    
    
      <li><a href="./series/">By series</a></li>
    
    
      <li><a href="./tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="./atom.xml">RSS</a></li>
</ul></nav>

  <hr />
</div>

<div class="main-menu bottom">
  <hr />
  <nav><ul>
    
      <li class="inactive"><strong>Home</strong></li>
    
    
      <li><a href="./posts/">By date</a></li>
    
    
      <li><a href="./tags/">By tag</a></li>
    
    
      <li><a href="./series/">By series</a></li>
    
    
      <li><a href="./tag/meta/">Meta</a></li>
    
    <li class="rss"><a href="./atom.xml">RSS</a></li>
</ul></nav>

</div>


</div>

  </body>
</html>
